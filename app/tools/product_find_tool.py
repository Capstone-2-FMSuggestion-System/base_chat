import os
import sys
import logging
import asyncio
import json
from pinecone import Pinecone
from dotenv import load_dotenv
import google.generativeai as genai
from langchain_huggingface import HuggingFaceEmbeddings
from typing import Optional, Tuple

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from app.services.api_key_manager import get_api_key_manager

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# --- C·∫•u h√¨nh ---
PINECONE_API_KEY = os.getenv("PRODUCT_DB_PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "product-index")
GEMINI_MODEL_NAME = os.getenv("GEMINI_MODEL", "gemini-2.0-flash-lite")
EMBEDDING_MODEL_NAME = "sentence-transformers/all-mpnet-base-v2"
TOP_K_PRODUCTS_PER_INGREDIENT = 500
MAX_CONCURRENT_GEMINI_PRODUCT_CALLS = 3

api_key_manager = get_api_key_manager()

# Ki·ªÉm tra API keys
if not PINECONE_API_KEY or not PINECONE_INDEX_NAME:
    missing_keys = [
        key for key, value in {
            "PRODUCT_DB_PINECONE_API_KEY": PINECONE_API_KEY,
            "PINECONE_INDEX_NAME": PINECONE_INDEX_NAME
        }.items() if not value
    ]
    logger.error(f"C√°c bi·∫øn m√¥i tr∆∞·ªùng sau kh√¥ng ƒë∆∞·ª£c thi·∫øt l·∫≠p: {', '.join(missing_keys)}")
    raise ValueError(f"C√°c bi·∫øn m√¥i tr∆∞·ªùng sau kh√¥ng ƒë∆∞·ª£c thi·∫øt l·∫≠p: {', '.join(missing_keys)}")

if not api_key_manager.is_healthy():
    logger.error("ApiKeyManager kh√¥ng kh·∫£ d·ª•ng. Ki·ªÉm tra c·∫•u h√¨nh API keys trong file .env")
    raise ValueError("ApiKeyManager kh√¥ng kh·∫£ d·ª•ng. Ki·ªÉm tra c·∫•u h√¨nh API keys trong file .env")

logger.info(f"‚úÖ Product Find Tool ƒë√£ kh·ªüi t·∫°o v·ªõi {len(api_key_manager.get_all_keys())} API keys c√≥ s·∫µn")


def init_services():
    """Kh·ªüi t·∫°o k·∫øt n·ªëi Pinecone v√† embedding model."""
    try:
        pc = Pinecone(api_key=PINECONE_API_KEY)
        try:
            index_info = pc.describe_index(PINECONE_INDEX_NAME)
            logger.info(f"Pinecone index '{PINECONE_INDEX_NAME}' ƒë√£ t·ªìn t·∫°i")
        except Exception as e:
            logger.error(f"Pinecone index '{PINECONE_INDEX_NAME}' kh√¥ng t·ªìn t·∫°i ho·∫∑c l·ªói khi truy c·∫≠p: {str(e)}")
            raise ValueError(f"Pinecone index '{PINECONE_INDEX_NAME}' kh√¥ng t·ªìn t·∫°i.") from e

        pinecone_index = pc.Index(PINECONE_INDEX_NAME)
        logger.info(f"ƒê√£ t·∫°o ƒë·ªëi t∆∞·ª£ng Index cho: {PINECONE_INDEX_NAME}")

        logger.info(f"ƒêang t·∫£i m√¥ h√¨nh embedding t·ª´ {EMBEDDING_MODEL_NAME}...")
        embeddings_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        logger.info("ƒê√£ t·∫£i th√†nh c√¥ng m√¥ h√¨nh embedding.")

        return pinecone_index, embeddings_model
    except Exception as e:
        logger.error(f"L·ªói khi kh·ªüi t·∫°o k·∫øt n·ªëi d·ªãch v·ª•: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise


async def call_gemini_api_generic_async(prompt: str, task_description: str, max_retries: int = 3) -> str:
    """H√†m g·ªçi Gemini b·∫•t ƒë·ªìng b·ªô v·ªõi API key rotation."""
    loop = asyncio.get_event_loop()
    
    current_api_key = api_key_manager.get_next_key()
    if not current_api_key:
        error_msg = f"Kh√¥ng c√≥ API key kh·∫£ d·ª•ng cho {task_description}"
        logger.error(error_msg)
        return json.dumps({"error": error_msg})
    
    logger.info(f"üîë {task_description} s·ª≠ d·ª•ng key: {current_api_key[:10]}...")
    
    for attempt in range(max_retries):
        try:
            genai.configure(api_key=current_api_key)
            temp_gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)
            
            response = await loop.run_in_executor(
                None,
                lambda: temp_gemini_model.generate_content(
                    prompt,
                    generation_config={"max_output_tokens": 4096}
                )
            )
            
            if response.parts:
                return response.text
            else:
                logger.warning(f"Gemini kh√¥ng tr·∫£ v·ªÅ n·ªôi dung ({task_description}). Response: {response}")
                if response.prompt_feedback and response.prompt_feedback.block_reason:
                    logger.warning(f"B·ªã ch·∫∑n b·ªüi ({task_description}): {response.prompt_feedback.block_reason_message}")
                return json.dumps({"error": f"Gemini kh√¥ng tr·∫£ v·ªÅ n·ªôi dung ({task_description})."})
                
        except Exception as e:
            error_str = str(e).lower()
            
            if "429" in error_str or "resource_exhausted" in error_str or "too many requests" in error_str:
                retry_delay = 10 + attempt * 10
                logger.warning(f"L·ªói quota/rate limit Gemini ({task_description}), th·ª≠ l·∫°i sau {retry_delay} gi√¢y...")
                await asyncio.sleep(retry_delay)
                
            elif "invalid_argument" in error_str and ("token" in error_str or "request payload" in error_str or "size limit" in error_str):
                logger.error(f"L·ªói: Prompt qu√° l·ªõn ({task_description}). {str(e)}")
                return json.dumps({"error": f"Prompt qu√° l·ªõn cho model x·ª≠ l√Ω ({task_description})."})
                
            else:
                logger.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi g·ªçi API Gemini ({task_description}) (L·∫ßn {attempt+1}/{max_retries}): {str(e)}")
                if attempt == max_retries - 1:
                    return json.dumps({"error": f"L·ªói kh√¥ng x√°c ƒë·ªãnh v√† kh√¥ng th·ªÉ ph·ª•c h·ªìi t·ª´ Gemini ({task_description})."})
                await asyncio.sleep(15)
                
    logger.error(f"V·∫´n g·∫∑p l·ªói sau {max_retries} l·∫ßn th·ª≠ l·∫°i v·ªõi Gemini ({task_description}).")
    return json.dumps({"error": f"Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi Gemini sau nhi·ªÅu l·∫ßn th·ª≠ ({task_description})."})


async def analyze_user_request_with_gemini_async(user_request_text: str) -> dict:
    """B∆∞·ªõc 1: S·ª≠ d·ª•ng Gemini ƒë·ªÉ ph√¢n t√≠ch y√™u c·∫ßu ng∆∞·ªùi d√πng."""
    prompt = f"""
    Ph√¢n t√≠ch ƒëo·∫°n vƒÉn b·∫£n y√™u c·∫ßu sau c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ x√°c ƒë·ªãnh c√°c nguy√™n li·ªáu h·ªç c·∫ßn mua v√† t√™n m√≥n ƒÉn (n·∫øu c√≥).
    Y√™u c·∫ßu: "{user_request_text}"

    H√£y tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON DUY NH·∫§T c√≥ c√°c tr∆∞·ªùng sau:
    - "dish_name": (string) T√™n m√≥n ƒÉn ch√≠nh m√† ng∆∞·ªùi d√πng mu·ªën n·∫•u (n·∫øu c√≥ th·ªÉ x√°c ƒë·ªãnh, n·∫øu kh√¥ng th√¨ ƒë·ªÉ l√† null).
    - "requested_ingredients": (list of strings) Danh s√°ch c√°c t√™n nguy√™n li·ªáu m√† ng∆∞·ªùi d√πng ƒë·ªÅ c·∫≠p. C·ªë g·∫Øng chu·∫©n h√≥a t√™n g·ªçi n·∫øu c√≥ th·ªÉ (v√≠ d·ª•: "h√†nh c√¢y" -> "h√†nh l√°", "b·ªôt canh" -> "gia v·ªã n√™m").

    V√≠ d·ª•: N·∫øu input l√† "T√¥i mu·ªën n·∫•u canh chua c√° l√≥c, c·∫ßn mua c√° l√≥c, me, c√† chua, gi√° v√† √≠t rau th∆°m."
    Output mong mu·ªën:
    {{
        "dish_name": "Canh chua c√° l√≥c",
        "requested_ingredients": ["c√° l√≥c", "me", "c√† chua", "gi√° ƒë·ªó", "rau th∆°m"]
    }}

    N·∫øu input l√† "Cho t√¥i xin √≠t th·ªãt ba ch·ªâ, v√†i qu·∫£ c√† chua v√† h√†nh l√°."
    Output mong mu·ªën:
    {{
        "dish_name": null,
        "requested_ingredients": ["th·ªãt ba ch·ªâ", "c√† chua", "h√†nh l√°"]
    }}
    Ch·ªâ tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng JSON.
    """
    logger.info("G·ª≠i y√™u c·∫ßu ph√¢n t√≠ch nguy√™n li·ªáu ƒë·∫øn Gemini...")
    response_text = await call_gemini_api_generic_async(prompt, "Ph√¢n t√≠ch y√™u c·∫ßu ng∆∞·ªùi d√πng")
    
    try:
        cleaned_response_text = response_text.strip()
        if cleaned_response_text.startswith("```json"):
            cleaned_response_text = cleaned_response_text[7:]
        if cleaned_response_text.endswith("```"):
            cleaned_response_text = cleaned_response_text[:-3]
        
        analysis_result = json.loads(cleaned_response_text)
        if "error" in analysis_result:
            logger.error(f"L·ªói t·ª´ Gemini khi ph√¢n t√≠ch y√™u c·∫ßu: {analysis_result['error']}")
            return {"dish_name": None, "requested_ingredients": [], "error": analysis_result['error']}
        
        analysis_result.setdefault("dish_name", None)
        analysis_result.setdefault("requested_ingredients", [])
        logger.info(f"K·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ Gemini: {analysis_result}")
        return analysis_result
        
    except json.JSONDecodeError as e:
        logger.error(f"L·ªói gi·∫£i m√£ JSON t·ª´ ph√¢n t√≠ch y√™u c·∫ßu c·ªßa Gemini: {e}")
        logger.error(f"Ph·∫£n h·ªìi g·ªëc t·ª´ Gemini (ph√¢n t√≠ch): {response_text}")
        return {"dish_name": None, "requested_ingredients": [], "error": "L·ªói parse JSON ph√¢n t√≠ch y√™u c·∫ßu."}


async def find_product_for_ingredient_async(pinecone_index, embeddings_model, ingredient_name: str) -> Tuple[Optional[str], Optional[str]]:
    """
    B∆∞·ªõc 2 & 3: T√¨m v√† ch·ªçn product_id cho m·ªôt nguy√™n li·ªáu c·ª• th·ªÉ.
    Tr·∫£ v·ªÅ (product_id, product_name) ho·∫∑c (None, None) n·∫øu kh√¥ng t√¨m th·∫•y.
    """
    loop = asyncio.get_event_loop()
    pinecone_query_text = f"S·∫£n ph·∫©m cho nguy√™n li·ªáu: {ingredient_name}"
    
    try:
        query_vector = await loop.run_in_executor(None, embeddings_model.embed_query, pinecone_query_text)
    except Exception as e:
        logger.error(f"L·ªói khi nh√∫ng query cho nguy√™n li·ªáu '{ingredient_name}': {str(e)}")
        return None, None

    potential_products_context = []
    try:
        query_response = await loop.run_in_executor(
            None,
            lambda: pinecone_index.query(
                vector=query_vector,
                top_k=TOP_K_PRODUCTS_PER_INGREDIENT,
                include_metadata=True
            )
        )
        
        if query_response.matches:
            for match in query_response.matches:
                prod_id = match.metadata.get("doc_id")
                prod_name = match.metadata.get("name")
                if prod_id and prod_name:
                    potential_products_context.append({"id": prod_id, "name": prod_name})
                    
    except Exception as e:
        logger.error(f"L·ªói khi query Pinecone cho nguy√™n li·ªáu '{ingredient_name}': {str(e)}")
        return None, None

    if not potential_products_context:
        logger.info(f"Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ti·ªÅm nƒÉng n√†o tr√™n Pinecone cho nguy√™n li·ªáu: '{ingredient_name}'")
        return None, None

    potential_products_str = "\n".join([f"- ID: {p['id']}, T√™n S·∫£n Ph·∫©m: {p['name']}" for p in potential_products_context])
    prompt_for_selection = f"""
    Ng∆∞·ªùi d√πng c·∫ßn t√¨m s·∫£n ph·∫©m cho nguy√™n li·ªáu: "{ingredient_name}".
    D∆∞·ªõi ƒë√¢y l√† danh s√°ch c√°c s·∫£n ph·∫©m (ID v√† T√™n) c√≥ th·ªÉ li√™n quan ƒë∆∞·ª£c t√¨m th·∫•y:
    {potential_products_str}

    H√£y ch·ªçn ra s·∫£n ph·∫©m (ID v√† T√™n) PH√ô H·ª¢P NH·∫§T cho nguy√™n li·ªáu "{ingredient_name}".
    M·ªôt s·∫£n ph·∫©m ƒë∆∞·ª£c coi l√† ph√π h·ª£p n·∫øu t√™n c·ªßa n√≥ kh·ªõp ho·∫∑c l√† m·ªôt bi·∫øn th·ªÉ/lo·∫°i c·ª• th·ªÉ c·ªßa nguy√™n li·ªáu ƒë√≥.
    V√≠ d·ª•, n·∫øu ng∆∞·ªùi d√πng c·∫ßn "g√†", s·∫£n ph·∫©m "G√† ta nguy√™n con" ho·∫∑c "·ª®c g√†" c√≥ th·ªÉ ph√π h·ª£p.

    Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON DUY NH·∫§T c√≥ c√°c tr∆∞·ªùng:
    - "selected_product_id": (string) ID c·ªßa s·∫£n ph·∫©m b·∫°n ch·ªçn. N·∫øu kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ph√π h·ª£p, ƒë·ªÉ l√† null.
    - "selected_product_name": (string) T√™n c·ªßa s·∫£n ph·∫©m b·∫°n ch·ªçn. N·∫øu kh√¥ng c√≥, ƒë·ªÉ l√† null.

    V√≠ d·ª• ph·∫£n h·ªìi: {{"selected_product_id": "123", "selected_product_name": "G√† ta nguy√™n con"}}
    Ho·∫∑c n·∫øu kh√¥ng c√≥: {{"selected_product_id": null, "selected_product_name": null}}
    Ch·ªâ tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng JSON.
    """
    
    logger.info(f"G·ª≠i y√™u c·∫ßu ch·ªçn s·∫£n ph·∫©m cho nguy√™n li·ªáu '{ingredient_name}' ƒë·∫øn Gemini...")
    response_text = await call_gemini_api_generic_async(prompt_for_selection, f"Ch·ªçn s·∫£n ph·∫©m cho '{ingredient_name}'")
    
    try:
        cleaned_response_text = response_text.strip()
        if cleaned_response_text.startswith("```json"): 
            cleaned_response_text = cleaned_response_text[7:]
        if cleaned_response_text.endswith("```"): 
            cleaned_response_text = cleaned_response_text[:-3]
        
        selection_result = json.loads(cleaned_response_text)
        if "error" in selection_result:
            logger.error(f"L·ªói t·ª´ Gemini khi ch·ªçn s·∫£n ph·∫©m cho '{ingredient_name}': {selection_result['error']}")
            return None, None
        
        return selection_result.get("selected_product_id"), selection_result.get("selected_product_name")
        
    except json.JSONDecodeError as e:
        logger.error(f"L·ªói gi·∫£i m√£ JSON khi ch·ªçn s·∫£n ph·∫©m cho '{ingredient_name}': {e}")
        logger.error(f"Ph·∫£n h·ªìi g·ªëc t·ª´ Gemini (ch·ªçn s·∫£n ph·∫©m cho '{ingredient_name}'): {response_text}")
        return None, None


async def process_user_request_async(user_request_text: str) -> dict:
    """
    Quy tr√¨nh ch√≠nh: Ph√¢n t√≠ch y√™u c·∫ßu, t√¨m s·∫£n ph·∫©m cho t·ª´ng nguy√™n li·ªáu v·ªõi concurrency control.
    """
    loop = asyncio.get_event_loop()
    
    try:
        pinecone_index, embeddings_model = await loop.run_in_executor(None, init_services)
    except Exception as e:
        return {"error": f"L·ªói kh·ªüi t·∫°o d·ªãch v·ª•: {str(e)}", "results": []}

    analysis = await analyze_user_request_with_gemini_async(user_request_text)
    if "error" in analysis or not analysis.get("requested_ingredients"):
        return {
            "error": analysis.get("error", "Kh√¥ng th·ªÉ ph√¢n t√≠ch y√™u c·∫ßu ng∆∞·ªùi d√πng ho·∫∑c kh√¥ng t√¨m th·∫•y nguy√™n li·ªáu."),
            "dish_name_identified": analysis.get("dish_name"),
            "results": []
        }

    dish_name = analysis.get("dish_name")
    requested_ingredients = analysis.get("requested_ingredients", [])
    logger.info(f"M√≥n ƒÉn x√°c ƒë·ªãnh (n·∫øu c√≥): {dish_name}")
    logger.info(f"C√°c nguy√™n li·ªáu y√™u c·∫ßu (ƒë√£ chu·∫©n h√≥a b·ªüi Gemini): {requested_ingredients}")

    if not requested_ingredients:
        return {
            "dish_name_identified": dish_name,
            "processed_request": user_request_text,
            "ingredient_mapping_results": [],
            "ingredients_not_found_product_id": []
        }

    semaphore = asyncio.Semaphore(MAX_CONCURRENT_GEMINI_PRODUCT_CALLS)
    
    async def process_single_ingredient_with_semaphore(ingredient_name: str):
        async with semaphore:
            logger.info(f"ƒêang t√¨m s·∫£n ph·∫©m cho nguy√™n li·ªáu: '{ingredient_name}'...")
            product_id, product_name = await find_product_for_ingredient_async(pinecone_index, embeddings_model, ingredient_name)
            
            if product_id:
                result = {
                    "requested_ingredient": ingredient_name,
                    "product_id": product_id,
                    "product_name": product_name,
                    "status": "ƒê√£ t√¨m th·∫•y s·∫£n ph·∫©m"
                }
                logger.info(f"‚úÖ T√¨m th·∫•y s·∫£n ph·∫©m ID: {product_id}, T√™n: {product_name} cho nguy√™n li·ªáu '{ingredient_name}'")
            else:
                result = {
                    "requested_ingredient": ingredient_name,
                    "product_id": None,
                    "product_name": None,
                    "status": "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p"
                }
                logger.info(f"‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p cho nguy√™n li·ªáu: '{ingredient_name}'")
            
            return result

    tasks = [process_single_ingredient_with_semaphore(ingredient) for ingredient in requested_ingredients]
    logger.info(f"üîÑ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {len(tasks)} nguy√™n li·ªáu v·ªõi concurrency t·ªëi ƒëa {MAX_CONCURRENT_GEMINI_PRODUCT_CALLS}")
    
    ingredient_processing_results = await asyncio.gather(*tasks, return_exceptions=True)
    
    final_results = []
    ingredients_not_found = []
    
    for i, result in enumerate(ingredient_processing_results):
        if isinstance(result, Exception):
            ingredient_name = requested_ingredients[i]
            logger.error(f"‚ùå L·ªói khi x·ª≠ l√Ω nguy√™n li·ªáu '{ingredient_name}': {str(result)}")
            final_results.append({
                "requested_ingredient": ingredient_name,
                "product_id": None,
                "product_name": None,
                "status": f"L·ªói x·ª≠ l√Ω: {str(result)}"
            })
            ingredients_not_found.append(ingredient_name)
        else:
            final_results.append(result)
            if not result.get("product_id"):
                ingredients_not_found.append(result["requested_ingredient"])

    logger.info(f"üéØ Ho√†n th√†nh x·ª≠ l√Ω: {len(final_results)} nguy√™n li·ªáu, {len(ingredients_not_found)} kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m")

    return {
        "dish_name_identified": dish_name,
        "processed_request": user_request_text,
        "ingredient_mapping_results": final_results,
        "ingredients_not_found_product_id": ingredients_not_found
    }


async def main_test_product_async():
    """Test function for async product finding."""
    try:
        user_input_text = "T√¥i mu·ªën n·∫•u Ch√°o c√° gi√≤ heo, t√¥i c·∫ßn mua G·∫°o th∆°m, G·∫°o n·∫øp, Gi√≤ heo r√∫t x∆∞∆°ng, N·∫°c c√° l√≥c."
        
        print(f"\nƒêang x·ª≠ l√Ω y√™u c·∫ßu: '{user_input_text}'")
        
        import time
        start_time = time.time()
        result = await process_user_request_async(user_input_text)
        end_time = time.time()
        
        print(f"\n‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {end_time - start_time:.2f} gi√¢y")
        print("\n--- K·∫æT QU·∫¢ X·ª¨ L√ù Y√äU C·∫¶U ---")
        print(json.dumps(result, indent=2, ensure_ascii=False))

    except ValueError as ve: 
        print(f"L·ªói c·∫•u h√¨nh: {ve}")
    except Exception as e:
        logger.error(f"L·ªói kh√¥ng mong mu·ªën ·ªü main (product_find_tool): {str(e)}")
        import traceback
        logger.error(traceback.format_exc())


if __name__ == "__main__":
    asyncio.run(main_test_product_async())