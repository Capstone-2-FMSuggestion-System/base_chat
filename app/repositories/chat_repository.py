import json
import logging
from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
from sqlalchemy import desc, func

from app.db.models import Conversation, Message, User, HealthData, Menu, MenuItem
from app.services.cache_service import CacheService, invalidate_cache_on_update
from app.config import settings


logger = logging.getLogger(__name__)


class ChatRepository:
    def __init__(self, db: Session):
        self.db = db

    def create_conversation(self, user_id: int, title: str = None) -> Conversation:
        """T·∫°o cu·ªôc tr√≤ chuy·ªán m·ªõi"""
        conversation = Conversation(user_id=user_id, title=title)
        self.db.add(conversation)
        self.db.commit()
        self.db.refresh(conversation)

        CacheService.cache_conversation_metadata(
            conversation.conversation_id,
            user_id,
            title,
            conversation.created_at,
            conversation.updated_at
        )
        return conversation

    def add_message(self, conversation_id: int, role: str, content: str, is_summarized: bool = False) -> Message:
        """
        Th√™m tin nh·∫Øn m·ªõi v√†o cu·ªôc tr√≤ chuy·ªán.
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán
            role: Vai tr√≤ (user/assistant/system)
            content: N·ªôi dung tin nh·∫Øn
            is_summarized: M·∫∑c ƒë·ªãnh False - ch·ªâ True n·∫øu tin nh·∫Øn n√†y T·ª∞ N√ì l√† m·ªôt b·∫£n t√≥m t·∫Øt
            
        Returns:
            Message object ƒë√£ ƒë∆∞·ª£c t·∫°o
            
        Note:
            - Tr∆∞·ªùng 'summary' lu√¥n ƒë∆∞·ª£c ƒë·∫∑t l√† None khi t·∫°o tin nh·∫Øn m·ªõi
            - Vi·ªác c·∫≠p nh·∫≠t summary s·∫Ω ƒë∆∞·ª£c th·ª±c hi·ªán ri√™ng b·ªüi save_conversation_summary()
            - is_summarized=False ƒë·∫£m b·∫£o tin nh·∫Øn s·∫Ω ƒë∆∞·ª£c xem x√©t cho vi·ªác t√≥m t·∫Øt sau n√†y
        """
        message = Message(
            conversation_id=conversation_id,
            role=role,
            content=content,
            is_summarized=False,  # Lu√¥n False cho tin nh·∫Øn m·ªõi - s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t khi c√≥ t√≥m t·∫Øt
            summary=None  # Lu√¥n None ban ƒë·∫ßu - s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t b·ªüi save_conversation_summary
        )
        self.db.add(message)

        # C·∫≠p nh·∫≠t timestamp cu·ªôc tr√≤ chuy·ªán
        conversation = self.get_conversation_by_id(conversation_id)
        if conversation:
            conversation.updated_at = datetime.now()

        self.db.commit()
        self.db.refresh(message)

        # Invalidate caches li√™n quan ƒë·ªÉ ƒë·∫£m b·∫£o consistency
        self._rebuild_messages_cache(conversation_id)
        self._sync_related_caches(conversation_id)
        
        # Invalidate cache t√≥m t·∫Øt v√¨ c√≥ tin nh·∫Øn m·ªõi
        summary_cache_key = CacheService._get_cache_key(
            CacheService.CONVERSATION_METADATA, 
            conversation_id=f"{conversation_id}_latest_summary"
        )
        CacheService.delete_cache(summary_cache_key)

        return message

    def get_latest_summary(self, conversation_id: int) -> Optional[str]:
        """
        L·∫•y b·∫£n t√≥m t·∫Øt "cu·ªôn" g·∫ßn nh·∫•t c·ªßa cu·ªôc tr√≤ chuy·ªán.
        
        Logic:
        1. Th·ª≠ l·∫•y t·ª´ Redis cache tr∆∞·ªõc (O(1))
        2. N·∫øu cache miss: Query DB t√¨m assistant message g·∫ßn nh·∫•t c√≥ summary
        3. Cache k·∫øt qu·∫£ ƒë·ªÉ t·ªëi ∆∞u cho l·∫ßn sau
        4. N·∫øu kh√¥ng t√¨m th·∫•y: cache empty string v·ªõi TTL ng·∫Øn ƒë·ªÉ tr√°nh query li√™n t·ª•c
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán
            
        Returns:
            B·∫£n t√≥m t·∫Øt cu·ªëi c√πng ho·∫∑c None n·∫øu ch∆∞a c√≥ t√≥m t·∫Øt n√†o
        """
        # T·∫°o cache key nh·∫•t qu√°n cho latest summary
        cache_key = CacheService._get_cache_key(
            CacheService.CONVERSATION_METADATA, 
            conversation_id=f"{conversation_id}_latest_summary"
        )

        # B∆∞·ªõc 1: Th·ª≠ l·∫•y t·ª´ cache tr∆∞·ªõc
        cached_summary = CacheService.get_cache(cache_key, expected_type=str)
        if cached_summary is not None:
            logger.debug(f"‚úÖ Cache hit - L·∫•y t√≥m t·∫Øt t·ª´ cache cho conversation_id={conversation_id}")
            # Tr·∫£ v·ªÅ None n·∫øu cache ch·ª©a empty string (ƒë√°nh d·∫•u kh√¥ng c√≥ t√≥m t·∫Øt)
            return cached_summary if cached_summary else None

        # B∆∞·ªõc 2: Cache miss - Query DB ƒë·ªÉ t√¨m assistant message g·∫ßn nh·∫•t c√≥ summary
        logger.debug(f"üîç Cache miss - Query DB t√¨m t√≥m t·∫Øt cho conversation_id={conversation_id}")
        
        latest_assistant_message_with_summary = self.db.query(Message)\
            .filter(
                Message.conversation_id == conversation_id,
                Message.role == "assistant",
                Message.summary.isnot(None),
                Message.summary != ""
            )\
            .order_by(desc(Message.created_at))\
            .first()

        if latest_assistant_message_with_summary:
            summary_text = latest_assistant_message_with_summary.summary
            logger.info(f"üìù T√¨m th·∫•y t√≥m t·∫Øt t·ª´ DB cho conversation_id={conversation_id} (message_id={latest_assistant_message_with_summary.message_id})")
            
            # B∆∞·ªõc 3: Cache k·∫øt qu·∫£ v·ªõi TTL medium
            CacheService.set_cache(cache_key, summary_text, ttl=CacheService.TTL_MEDIUM)
            return summary_text
        
        # B∆∞·ªõc 4: Kh√¥ng t√¨m th·∫•y t√≥m t·∫Øt - cache empty string v·ªõi TTL ng·∫Øn
        logger.debug(f"‚ùå Kh√¥ng t√¨m th·∫•y t√≥m t·∫Øt cho conversation_id={conversation_id}")
        CacheService.set_cache(cache_key, "", ttl=CacheService.TTL_SHORT)
        return None

    def save_conversation_summary(self, conversation_id: int, assistant_message_id: int, summary_text: str) -> bool:
        """
        L∆∞u b·∫£n t√≥m t·∫Øt tƒÉng d·∫ßn v√†o tr∆∞·ªùng summary c·ªßa tin nh·∫Øn assistant.
        ƒê·∫£m b·∫£o t√≠nh nh·∫•t qu√°n gi·ªØa DB v√† cache.
        
        Logic:
        1. T√¨m assistant message theo ID v√† conversation_id
        2. C·∫≠p nh·∫≠t summary v√† ƒë√°nh d·∫•u is_summarized=True cho assistant message
        3. T√¨m user message ngay tr∆∞·ªõc ƒë√≥ v√† ƒë√°nh d·∫•u is_summarized=True
        4. Commit DB transaction
        5. C·∫≠p nh·∫≠t cache v·ªõi summary m·ªõi
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán
            assistant_message_id: ID tin nh·∫Øn assistant c·∫ßn l∆∞u t√≥m t·∫Øt
            summary_text: N·ªôi dung t√≥m t·∫Øt
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu c√≥ l·ªói
        """
        try:
            # B∆∞·ªõc 1: T√¨m assistant message
            assistant_message = self.db.query(Message).filter(
                Message.message_id == assistant_message_id,
                Message.conversation_id == conversation_id,
                Message.role == "assistant"
            ).first()

            if not assistant_message:
                logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y assistant_message_id={assistant_message_id} trong conversation_id={conversation_id}")
                return False

            # B∆∞·ªõc 2: C·∫≠p nh·∫≠t summary cho assistant message
            assistant_message.summary = summary_text
            assistant_message.is_summarized = True
            assistant_message.updated_at = datetime.now()
            
            # B∆∞·ªõc 3: T√¨m v√† ƒë√°nh d·∫•u user message ngay tr∆∞·ªõc ƒë√≥
            user_message_before_assistant = self.db.query(Message).filter(
                Message.conversation_id == conversation_id,
                Message.role == "user",
                Message.created_at < assistant_message.created_at
            ).order_by(desc(Message.created_at)).first()

            if user_message_before_assistant and not user_message_before_assistant.is_summarized:
                user_message_before_assistant.is_summarized = True
                user_message_before_assistant.updated_at = datetime.now()
                logger.debug(f"‚úÖ ƒê√°nh d·∫•u user_message_id={user_message_before_assistant.message_id} ƒë√£ ƒë∆∞·ª£c t√≥m t·∫Øt")

            # B∆∞·ªõc 4: Commit transaction
            self.db.commit()
            logger.info(f"üíæ ƒê√£ l∆∞u t√≥m t·∫Øt cho assistant_message_id={assistant_message_id}, ƒë·ªô d√†i: {len(summary_text)} k√Ω t·ª±")

            # B∆∞·ªõc 5: C·∫≠p nh·∫≠t cache
            cache_key = CacheService._get_cache_key(
                CacheService.CONVERSATION_METADATA, 
                conversation_id=f"{conversation_id}_latest_summary"
            )
            cache_success = CacheService.set_cache(cache_key, summary_text, ttl=CacheService.TTL_MEDIUM)
            
            if cache_success:
                logger.debug(f"üîÑ ƒê√£ c·∫≠p nh·∫≠t cache t√≥m t·∫Øt cho conversation_id={conversation_id}")
            else:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t cache t√≥m t·∫Øt - DB ƒë√£ l∆∞u th√†nh c√¥ng")
            
            # Invalidate c√°c cache li√™n quan
            self._invalidate_summary_related_caches(conversation_id)
            
            return True

        except Exception as e:
            # Rollback transaction n·∫øu c√≥ l·ªói
            self.db.rollback()
            logger.error(f"üí• L·ªói khi l∆∞u t√≥m t·∫Øt cho assistant_message_id={assistant_message_id}: {str(e)}", exc_info=True)
            return False

    def get_messages_for_summary_context(self, conversation_id: int, limit: int = 3) -> List[Dict[str, str]]:
        """
        L·∫•y tin nh·∫Øn g·∫ßn nh·∫•t ƒë·ªÉ l√†m ng·ªØ c·∫£nh cho vi·ªác t·∫°o t√≥m t·∫Øt tƒÉng d·∫ßn.
        
        Logic:
        1. L·∫•y limit*2 tin nh·∫Øn cu·ªëi c√πng t·ª´ DB (ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ ƒë·ªß c·∫£ user v√† assistant)
        2. S·∫Øp x·∫øp theo th·ª© t·ª± th·ªùi gian tƒÉng d·∫ßn (gi·ªØ ƒë√∫ng flow h·ªôi tho·∫°i)
        3. Gi·ªõi h·∫°n k·∫øt qu·∫£ theo limit
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán
            limit: S·ªë l∆∞·ª£ng tin nh·∫Øn t·ªëi ƒëa c·∫ßn l·∫•y
            
        Returns:
            List c√°c dict {"role": "...", "content": "..."} theo th·ª© t·ª± th·ªùi gian
        """
        try:
            # L·∫•y limit*2 tin nh·∫Øn cu·ªëi ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ ƒë·ªß context
            messages_db = self.db.query(Message)\
                .filter(Message.conversation_id == conversation_id)\
                .order_by(desc(Message.created_at))\
                .limit(limit * 2)\
                .all()
            
            if not messages_db:
                logger.debug(f"Kh√¥ng c√≥ tin nh·∫Øn n√†o cho conversation_id={conversation_id}")
                return []

            # ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ c√≥ th·ª© t·ª± th·ªùi gian tƒÉng d·∫ßn (ƒë√∫ng flow h·ªôi tho·∫°i)
            formatted_messages = []
            for msg in reversed(messages_db):
                formatted_messages.append({
                    "role": msg.role, 
                    "content": msg.content,
                    "created_at": msg.created_at.isoformat() if hasattr(msg, 'created_at') else None
                })

            # Gi·ªõi h·∫°n k·∫øt qu·∫£ theo limit
            result = formatted_messages[-limit:] if len(formatted_messages) > limit else formatted_messages
            
            logger.debug(f"üìã L·∫•y {len(result)} tin nh·∫Øn context cho conversation_id={conversation_id}")
            return result

        except Exception as e:
            logger.error(f"üí• L·ªói khi l·∫•y tin nh·∫Øn context cho conversation_id={conversation_id}: {str(e)}", exc_info=True)
            return []

    def get_conversation_by_id(self, conversation_id: int) -> Optional[Conversation]:
        cached_metadata = CacheService.get_conversation_metadata(conversation_id)
        if cached_metadata:
            try:
                conv = Conversation()
                for key, value in cached_metadata.items():
                    if hasattr(conv, key) and value is not None:
                        if key in ['created_at', 'updated_at']:
                            setattr(conv, key, datetime.fromisoformat(value))
                        else:
                            setattr(conv, key, value)
                return conv
            except (KeyError, ValueError, TypeError) as e:
                logger.error(f"L·ªói parse conversation cache: {str(e)}")
                CacheService.delete_cache(CacheService._get_cache_key(CacheService.CONVERSATION_METADATA, conversation_id=conversation_id))

        conversation = self.db.query(Conversation).filter(Conversation.conversation_id == conversation_id).first()
        if conversation:
            CacheService.cache_conversation_metadata(
                conversation.conversation_id, conversation.user_id, conversation.title,
                conversation.created_at, conversation.updated_at
            )
        return conversation

    def get_latest_conversation(self, user_id: int) -> Optional[Conversation]:
        cached_conversation_id = CacheService.get_latest_conversation_id(user_id)
        if cached_conversation_id:
            conversation = self.get_conversation_by_id(cached_conversation_id)
            if conversation:
                return conversation

        conversation = self.db.query(Conversation).filter(
            Conversation.user_id == user_id
        ).order_by(desc(Conversation.updated_at)).first()

        if conversation:
            CacheService.cache_conversation_metadata(
                conversation.conversation_id,
                user_id,
                conversation.title,
                conversation.created_at,
                conversation.updated_at
            )
        return conversation

    def get_messages(self, conversation_id: int, limit: int = None) -> List[Dict[str, str]]:
        if limit is None:
            limit = settings.MAX_HISTORY_MESSAGES

        cache_key = CacheService._get_cache_key(CacheService.CONVERSATION_MESSAGES, conversation_id=conversation_id)

        def rebuild_messages_from_db():
            logger.debug(f"Rebuilding messages t·ª´ DB cho conversation_id={conversation_id}")
            messages_query = self.db.query(Message).filter(
                Message.conversation_id == conversation_id
            ).order_by(Message.created_at)
            
            all_messages_db = messages_query.all()
            formatted_msgs = [{"role": msg.role, "content": msg.content} for msg in all_messages_db]
            logger.info(f"ƒê√£ rebuild {len(formatted_msgs)} tin nh·∫Øn t·ª´ DB")
            return formatted_msgs

        all_cached_messages = CacheService.get_or_rebuild_cache(
            key=cache_key,
            rebuild_func=rebuild_messages_from_db,
            expected_type=list,
            ttl=CacheService.TTL_MEDIUM
        )

        if not all_cached_messages:
            return []

        if limit > 0 and len(all_cached_messages) > limit:
            return all_cached_messages[-limit:]
        return all_cached_messages

    def get_messages_with_summary(self, conversation_id: int, limit: int = None) -> List[Dict[str, str]]:
        """
        ƒê∆°n gi·∫£n h√≥a - ch·ªâ tr·∫£ v·ªÅ tin nh·∫Øn th√¥.
        ChatService s·∫Ω ch·ªãu tr√°ch nhi·ªám k·∫øt h·ª£p tin nh·∫Øn v√† t√≥m t·∫Øt n·∫øu c·∫ßn.
        
        Note: H√†m n√†y ƒë∆∞·ª£c gi·ªØ l·∫°i ƒë·ªÉ t∆∞∆°ng th√≠ch ng∆∞·ª£c,
        nh∆∞ng logic t√≥m t·∫Øt tƒÉng d·∫ßn ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi ChatService.
        """
        return self.get_messages(conversation_id, limit)

    def get_unsummarized_conversation_ids(self, threshold: int = None) -> List[int]:
        if threshold is None:
            threshold = settings.SUMMARY_THRESHOLD
            
        cached_result = CacheService.get_unsummarized_conversations(threshold)
        if cached_result is not None:
            return cached_result
        
        try:
            conversation_ids_query = self.db.query(Message.conversation_id).filter(
                Message.is_summarized == False,
                Message.role != "system"
            ).group_by(Message.conversation_id).having(
                func.count(Message.message_id) >= threshold
            )
            conversation_ids = conversation_ids_query.all()
            result = [conv_id[0] for conv_id in conversation_ids]
        except Exception as e:
            logger.error(f"L·ªói query unsummarized conversations: {e}")
            all_convs_with_unsummarized = self.db.query(Message.conversation_id).filter(
                Message.is_summarized == False, Message.role != "system"
            ).distinct().all()
            result = []
            for conv_id_tuple in all_convs_with_unsummarized:
                conv_id = conv_id_tuple[0]
                count = self.db.query(func.count(Message.message_id)).filter(
                    Message.conversation_id == conv_id,
                    Message.is_summarized == False,
                    Message.role != "system"
                ).scalar()
                if count >= threshold:
                    result.append(conv_id)

        CacheService.cache_unsummarized_conversations(threshold, result)
        return result

    def is_user_owner_of_conversation(self, user_id: int, conversation_id: int) -> bool:
        cached_owner = CacheService.get_conversation_owner(conversation_id)
        if cached_owner is not None:
            return cached_owner == user_id
            
        conversation = self.db.query(Conversation).filter(Conversation.conversation_id == conversation_id).first()
        if conversation:
            CacheService.cache_conversation_metadata(
                conversation.conversation_id, conversation.user_id, conversation.title,
                conversation.created_at, conversation.updated_at
            )
            return conversation.user_id == user_id
        return False

    def save_health_data(self, conversation_id: int, user_id: int, health_condition: str = None, 
                        medical_history: str = None, allergies: str = None, dietary_habits: str = None, 
                        health_goals: str = None, additional_info: Dict = None, data: Dict = None) -> HealthData:
        """
        L∆∞u th√¥ng tin s·ª©c kh·ªèe v·ªõi x·ª≠ l√Ω th√¥ng minh c√°c gi√° tr·ªã r·ªóng t·ª´ collected_info.
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán
            user_id: ID ng∆∞·ªùi d√πng
            health_condition: T√¨nh tr·∫°ng s·ª©c kh·ªèe
            medical_history: L·ªãch s·ª≠ b·ªánh √°n
            allergies: D·ªã ·ª©ng
            dietary_habits: Th√≥i quen ƒÉn u·ªëng
            health_goals: M·ª•c ti√™u s·ª©c kh·ªèe
            additional_info: Th√¥ng tin b·ªï sung
            data: Dictionary ch·ª©a d·ªØ li·ªáu t·ª´ collected_info (∆∞u ti√™n cao h∆°n c√°c tham s·ªë ri√™ng l·∫ª)
        
        Returns:
            HealthData object ƒë√£ ƒë∆∞·ª£c l∆∞u
        """
        try:
            logger.info(f"L∆∞u th√¥ng tin s·ª©c kh·ªèe: conv_id={conversation_id}")
            existing_data = self.db.query(HealthData).filter(HealthData.conversation_id == conversation_id).first()
            
            # N·∫øu c√≥ data t·ª´ collected_info, ∆∞u ti√™n s·ª≠ d·ª•ng n√≥
            if data:
                health_condition = data.get('health_condition', health_condition)
                medical_history = data.get('medical_history', medical_history)
                allergies = data.get('allergies', allergies)
                dietary_habits = data.get('dietary_habits', dietary_habits)
                health_goals = data.get('health_goals', health_goals)
                
                # X·ª≠ l√Ω additional_info t·ª´ data
                if not additional_info:
                    additional_info = {}
                
                # Th√™m food_preferences v√† food_dislikes t·ª´ data v√†o additional_info
                if data.get('food_preferences') is not None:
                    additional_info['food_preferences'] = data.get('food_preferences')
                if data.get('food_dislikes') is not None:
                    additional_info['food_dislikes'] = data.get('food_dislikes')
                
                # Th√™m c√°c tr∆∞·ªùng kh√°c t·ª´ data v√†o additional_info (ngo√†i c√°c tr∆∞·ªùng c∆° b·∫£n)
                excluded_fields = ['health_condition', 'medical_history', 'allergies', 'dietary_habits', 'health_goals', 'food_preferences', 'food_dislikes']
                for k, v in data.items():
                    if k not in excluded_fields and v is not None:
                        additional_info[k] = v
            
            if existing_data:
                # H√†m helper ƒë·ªÉ c·∫≠p nh·∫≠t tr∆∞·ªùng v·ªõi logic tr√°nh ghi ƒë√® b·∫±ng chu·ªói r·ªóng
                def update_field_safely(field_name: str, new_value: str, current_value: str) -> str:
                    """
                    C·∫≠p nh·∫≠t tr∆∞·ªùng m·ªôt c√°ch an to√†n:
                    - N·∫øu new_value l√† None: cho ph√©p x√≥a (tr·∫£ v·ªÅ None)
                    - N·∫øu new_value l√† chu·ªói r·ªóng v√† current_value c√≥ gi√° tr·ªã: gi·ªØ nguy√™n current_value
                    - Ng∆∞·ª£c l·∫°i: c·∫≠p nh·∫≠t v·ªõi new_value
                    """
                    if new_value is None:
                        return None  # Cho ph√©p x√≥a gi√° tr·ªã
                    elif isinstance(new_value, str) and new_value.strip() == "" and current_value:
                        logger.debug(f"Gi·ªØ nguy√™n {field_name} hi·ªán c√≥ (kh√¥ng ghi ƒë√® b·∫±ng chu·ªói r·ªóng)")
                        return current_value  # Gi·ªØ nguy√™n gi√° tr·ªã hi·ªán c√≥
                    else:
                        return new_value  # C·∫≠p nh·∫≠t v·ªõi gi√° tr·ªã m·ªõi
                
                # √Åp d·ª•ng logic c·∫≠p nh·∫≠t an to√†n cho c√°c tr∆∞·ªùng c∆° b·∫£n
                existing_data.health_condition = update_field_safely(
                    "health_condition", health_condition, existing_data.health_condition
                )
                existing_data.medical_history = update_field_safely(
                    "medical_history", medical_history, existing_data.medical_history
                )
                existing_data.allergies = update_field_safely(
                    "allergies", allergies, existing_data.allergies
                )
                existing_data.dietary_habits = update_field_safely(
                    "dietary_habits", dietary_habits, existing_data.dietary_habits
                )
                existing_data.health_goals = update_field_safely(
                    "health_goals", health_goals, existing_data.health_goals
                )
                
                # X·ª≠ l√Ω additional_info v·ªõi merge th√¥ng minh
                if additional_info:
                    # ƒê·∫£m b·∫£o existing additional_info t·ªìn t·∫°i
                    if not existing_data.additional_info:
                        existing_data.additional_info = {}
                    
                    # Merge t·ª´ng tr∆∞·ªùng trong additional_info v·ªõi logic an to√†n
                    for key, value in additional_info.items():
                        if value is not None:
                            if isinstance(value, str) and value.strip() == "" and existing_data.additional_info.get(key):
                                # Kh√¥ng ghi ƒë√® gi√° tr·ªã hi·ªán c√≥ b·∫±ng chu·ªói r·ªóng
                                logger.debug(f"Gi·ªØ nguy√™n additional_info['{key}'] hi·ªán c√≥ (kh√¥ng ghi ƒë√® b·∫±ng chu·ªói r·ªóng)")
                            else:
                                existing_data.additional_info[key] = value
                        
                existing_data.updated_at = datetime.now()
                self.db.commit()
                
                health_data_dict = self._format_health_data_for_cache(existing_data)
                CacheService.cache_health_data(conversation_id, health_data_dict)
                logger.info(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t th√¥ng tin s·ª©c kh·ªèe cho conversation_id={conversation_id}")
                return existing_data
            else:
                health_data = HealthData(
                    conversation_id=conversation_id, user_id=user_id,
                    health_condition=health_condition,
                    medical_history=medical_history,
                    allergies=allergies,
                    dietary_habits=dietary_habits,
                    health_goals=health_goals,
                    additional_info=additional_info or {}
                )
                self.db.add(health_data)
                self.db.commit()
                self.db.refresh(health_data)
                
                health_data_dict = self._format_health_data_for_cache(health_data)
                CacheService.cache_health_data(conversation_id, health_data_dict)
                logger.info(f"‚úÖ ƒê√£ t·∫°o m·ªõi th√¥ng tin s·ª©c kh·ªèe cho conversation_id={conversation_id}")
                return health_data
                
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u th√¥ng tin s·ª©c kh·ªèe: {str(e)}", exc_info=True)
            self.db.rollback()
            raise

    def get_health_data(self, conversation_id: int) -> Optional[Dict[str, Any]]:
        cached_data = CacheService.get_health_data(conversation_id)
        if cached_data:
            return cached_data
            
        health_data = self.db.query(HealthData).filter(
            HealthData.conversation_id == conversation_id
        ).order_by(desc(HealthData.updated_at)).first()
        
        if not health_data:
            return None
            
        result = self._format_health_data_for_cache(health_data)
        CacheService.cache_health_data(conversation_id, result)
        return result

    def _format_health_data_for_cache(self, health_data: HealthData) -> Dict[str, Any]:
        return {
            "user_id": health_data.user_id,
            "health_condition": health_data.health_condition,
            "medical_history": health_data.medical_history,
            "allergies": health_data.allergies,
            "dietary_habits": health_data.dietary_habits,
            "health_goals": health_data.health_goals,
            "additional_info": health_data.additional_info or {},
            "created_at": health_data.created_at.isoformat() if health_data.created_at else None,
            "updated_at": health_data.updated_at.isoformat() if health_data.updated_at else None
        }

    def _rebuild_messages_cache(self, conversation_id: int) -> bool:
        """
        Rebuild cache tin nh·∫Øn t·ª´ DB ƒë·ªÉ ƒë·∫£m b·∫£o consistency.
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán c·∫ßn rebuild cache
            
        Returns:
            True n·∫øu rebuild th√†nh c√¥ng, False n·∫øu c√≥ l·ªói
        """
        try:
            # Query t·∫•t c·∫£ tin nh·∫Øn t·ª´ DB theo th·ª© t·ª± th·ªùi gian
            messages_query = self.db.query(Message).filter(
                Message.conversation_id == conversation_id
            ).order_by(Message.created_at)
            
            all_messages_db = messages_query.all()
            formatted_messages = [
                {"role": msg.role, "content": msg.content} 
                for msg in all_messages_db
            ]
            
            # Cache v·ªõi key nh·∫•t qu√°n
            cache_key = CacheService._get_cache_key(
                CacheService.CONVERSATION_MESSAGES, 
                conversation_id=conversation_id
            )
            success = CacheService.set_cache(cache_key, formatted_messages, CacheService.TTL_MEDIUM)
            
            if success:
                logger.debug(f"üîÑ ƒê√£ rebuild messages cache cho conversation_id={conversation_id} ({len(formatted_messages)} tin nh·∫Øn)")
                return True
            else:
                logger.error(f"‚ùå L·ªói set cache khi rebuild cho conversation_id={conversation_id}")
                return False
            
        except Exception as e:
            logger.error(f"üí• L·ªói khi rebuild cache tin nh·∫Øn cho conversation_id={conversation_id}: {str(e)}", exc_info=True)
            return False

    def _sync_related_caches(self, conversation_id: int) -> None:
        """
        ƒê·ªìng b·ªô c√°c cache li√™n quan khi c√≥ thay ƒë·ªïi conversation.
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán c·∫ßn sync cache
        """
        try:
            conversation = self.db.query(Conversation).filter(
                Conversation.conversation_id == conversation_id
            ).first()
            
            if conversation:
                # Cache conversation metadata
                CacheService.cache_conversation_metadata(
                    conversation.conversation_id, conversation.user_id, conversation.title,
                    conversation.created_at, conversation.updated_at
                )
                
                # Cache latest conversation cho user
                latest_key = CacheService._get_cache_key(
                    CacheService.USER_LATEST_CONVERSATION, 
                    user_id=conversation.user_id
                )
                CacheService.set_cache(latest_key, conversation_id, CacheService.TTL_MEDIUM)
                
                logger.debug(f"üîÑ ƒê√£ sync related caches cho conversation_id={conversation_id}")
            else:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y conversation_id={conversation_id} ƒë·ªÉ sync cache")
            
        except Exception as e:
            logger.error(f"üí• L·ªói khi sync related caches cho conversation_id={conversation_id}: {str(e)}", exc_info=True)

    @invalidate_cache_on_update(["recent_recipes:*", "recipe:*:details"])
    def save_recipe_to_menu(self, recipe_name: str, recipe_description: str, 
                           ingredients_with_products: List[Dict[str, Any]]) -> Optional[int]:
        try:
            menu = Menu(name=recipe_name, description=recipe_description)
            self.db.add(menu)
            self.db.flush()
            
            menu_id = menu.menu_id
            logger.info(f"ƒê√£ t·∫°o menu '{recipe_name}' v·ªõi ID={menu_id}")
            
            menu_items_data = []
            ingredients_saved_count = 0
            
            # ‚≠ê L∆ØU T·∫§T C·∫¢ NGUY√äN LI·ªÜU, PRODUCT_ID C√ì TH·ªÇ NULL
            for ing in ingredients_with_products:
                ingredient_name = ing.get('ingredient_name', '').strip()
                product_id = ing.get('product_id')
                quantity = ing.get('quantity', 1)
                
                if ingredient_name:  # Ch·ªâ c·∫ßn c√≥ t√™n nguy√™n li·ªáu
                    menu_item = MenuItem(
                        menu_id=menu_id,
                        product_id=product_id,  # C√≥ th·ªÉ l√† None
                        quantity=quantity
                    )
                    self.db.add(menu_item)
                    ingredients_saved_count += 1
                    
                    menu_items_data.append({
                        'product_id': product_id,
                        'quantity': quantity,
                        'ingredient_name': ingredient_name
                    })
                    
            self.db.commit()
            
            recipe_data_cache = {
                'menu_id': menu_id,
                'name': recipe_name,
                'description': recipe_description,
                'created_at': datetime.now().isoformat(),
                'ingredients': menu_items_data
            }
            CacheService.cache_recipe_data(menu_id, recipe_data_cache)
            
            logger.info(f"ƒê√£ l∆∞u c√¥ng th·ª©c '{recipe_name}' v·ªõi {ingredients_saved_count} nguy√™n li·ªáu")
            return menu_id
            
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u c√¥ng th·ª©c '{recipe_name}': {str(e)}", exc_info=True)
            self.db.rollback()
            return None

    def save_multiple_recipes_to_menu(self, recipes_data: List[Dict[str, Any]], 
                                     product_mapping: Dict[str, Any]) -> List[int]:
        created_menu_ids = []
        if not recipes_data:
            return created_menu_ids
            
        # ‚≠ê X√ÇY D·ª∞NG MAPPING T·ª™ NGUY√äN LI·ªÜU ƒê·∫æN PRODUCT_ID
        ingredient_to_product = {}
        if product_mapping and product_mapping.get('ingredient_mapping_results'):
            for mapping in product_mapping['ingredient_mapping_results']:
                name_low = mapping.get('requested_ingredient', '').lower().strip()
                pid = mapping.get('product_id')
                if name_low and pid:
                    ingredient_to_product[name_low] = {
                        'product_id': int(pid),
                        'product_name': mapping.get('product_name', '')
                    }
        
        for recipe in recipes_data:
            try:
                name = recipe.get('name', 'M√≥n ƒÉn kh√¥ng t√™n')
                ing_sum = recipe.get('ingredients_summary', '')
                url = recipe.get('url', '')
                
                desc_parts = []
                if ing_sum:
                    desc_parts.append(f"Nguy√™n li·ªáu: {ing_sum}")
                if url:
                    desc_parts.append(f"Ngu·ªìn: {url}")
                    
                recipe_desc = "\n".join(desc_parts)
                ings_with_prods = []
                
                # ‚≠ê L∆ØU T·∫§T C·∫¢ NGUY√äN LI·ªÜU, KH√îNG CH·ªà NH·ªÆNG C√ÅI C√ì PRODUCT_ID
                if ing_sum:
                    for ing_item_str in ing_sum.split(','):
                        ing_clean = ing_item_str.strip()
                        if ing_clean:
                            ing_low = ing_clean.lower()
                            prod_info = None
                            
                            # T√¨m product_id n·∫øu c√≥
                            if ing_low in ingredient_to_product:
                                prod_info = ingredient_to_product[ing_low]
                            else:
                                for mapped_ing, info_map in ingredient_to_product.items():
                                    if mapped_ing in ing_low or ing_low in mapped_ing:
                                        prod_info = info_map
                                        break
                            
                            # ‚≠ê LU√îN TH√äM NGUY√äN LI·ªÜU V√ÄO DANH S√ÅCH, PRODUCT_ID C√ì TH·ªÇ NULL
                            ings_with_prods.append({
                                'ingredient_name': ing_clean,
                                'product_id': prod_info['product_id'] if prod_info else None,
                                'quantity': 1
                            })
                
                menu_id = self.save_recipe_to_menu(name, recipe_desc, ings_with_prods)
                if menu_id:
                    created_menu_ids.append(menu_id)
                else:
                    logger.warning(f"Kh√¥ng th·ªÉ l∆∞u recipe '{name}' t·ª´ batch")
                    
            except Exception as e:
                logger.error(f"L·ªói khi x·ª≠ l√Ω recipe '{recipe.get('name', 'Unknown')}': {str(e)}", exc_info=True)
                continue
        
        if created_menu_ids:
            batch_data_cache = {
                'menu_ids': created_menu_ids,
                'recipes_count': len(recipes_data),
                'recipes_summary': [
                    {
                        'name': r.get('name', ''),
                        'menu_id': created_menu_ids[i] if i < len(created_menu_ids) else None
                    }
                    for i, r in enumerate(recipes_data)
                ]
            }
            CacheService.cache_batch_operation("batch_recipe_save", batch_data_cache)
            
        logger.info(f"ƒê√£ l∆∞u {len(created_menu_ids)}/{len(recipes_data)} recipes v√†o database")
        return created_menu_ids

    def get_cached_recipes(self, limit: int = 20) -> Optional[List[Dict[str, Any]]]:
        cache_key = CacheService._get_cache_key(CacheService.RECENT_RECIPES, limit=limit)
        return CacheService.get_cache(cache_key, list)

    def get_recipe_by_id(self, menu_id: int) -> Optional[Dict[str, Any]]:
        cached_recipe = CacheService.get_recipe_data(menu_id)
        if cached_recipe:
            return cached_recipe
            
        menu = self.db.query(Menu).filter(Menu.menu_id == menu_id).first()
        if not menu:
            return None
            
        menu_items_db = self.db.query(MenuItem).filter(MenuItem.menu_id == menu_id).all()
        
        # ‚≠ê TR√çCH XU·∫§T INGREDIENT_NAME T·ª™ DESCRIPTION N·∫æU C√ì
        ingredients_list = []
        ingredient_names_from_desc = []
        
        # Parse ingredient names t·ª´ description n·∫øu c√≥
        if menu.description and "Nguy√™n li·ªáu:" in menu.description:
            desc_lines = menu.description.split('\n')
            for line in desc_lines:
                if line.startswith("Nguy√™n li·ªáu:"):
                    ingredients_text = line.replace("Nguy√™n li·ªáu:", "").strip()
                    ingredient_names_from_desc = [ing.strip() for ing in ingredients_text.split(',') if ing.strip()]
                    break
        
        # T·∫°o danh s√°ch ingredients v·ªõi t√™n n·∫øu c√≥
        for i, item in enumerate(menu_items_db):
            ingredient_name = None
            if i < len(ingredient_names_from_desc):
                ingredient_name = ingredient_names_from_desc[i]
            
            ingredients_list.append({
                'product_id': item.product_id,
                'quantity': item.quantity,
                'ingredient_name': ingredient_name
            })
        
        recipe_data_db = {
            'menu_id': menu.menu_id,
            'name': menu.name,
            'description': menu.description,
            'created_at': menu.created_at.isoformat() if menu.created_at else None,
            'ingredients': ingredients_list
        }
        
        CacheService.cache_recipe_data(menu_id, recipe_data_db)
        return recipe_data_db 

    def _invalidate_summary_related_caches(self, conversation_id: int) -> None:
        """Invalidate t·∫•t c·∫£ cache li√™n quan ƒë·∫øn t√≥m t·∫Øt khi c√≥ c·∫≠p nh·∫≠t"""
        try:
            summary_cache_key = CacheService._get_cache_key(
                CacheService.CONVERSATION_METADATA, 
                conversation_id=f"{conversation_id}_latest_summary"
            )
            CacheService.delete_cache(summary_cache_key)
            
            self._rebuild_messages_cache(conversation_id)
            self._sync_related_caches(conversation_id)
            
            logger.debug(f"üîÑ ƒê√£ invalidate cache t√≥m t·∫Øt cho conversation_id={conversation_id}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è L·ªói khi invalidate summary cache: {str(e)}")

    # === BACKGROUND DB OPERATIONS METHODS ===
    
    def prepare_add_message(self, conversation_id: int, role: str, content: str) -> Message:
        """
        Chu·∫©n b·ªã message object m√† kh√¥ng commit v√†o DB ngay.
        D√πng cho background processing.
        
        Returns:
            Message object ƒë√£ ƒë∆∞·ª£c add v√†o session nh∆∞ng ch∆∞a commit
        """
        message = Message(
            conversation_id=conversation_id,
            role=role,
            content=content,
            is_summarized=False,
            summary=None
        )
        self.db.add(message)
        
        # C·∫≠p nh·∫≠t timestamp cu·ªôc tr√≤ chuy·ªán
        conversation = self.get_conversation_by_id(conversation_id)
        if conversation:
            conversation.updated_at = datetime.now()
        
        # Ch∆∞a commit - s·∫Ω ƒë∆∞·ª£c commit ·ªü background
        logger.debug(f"üìù Prepared add_message for conversation_id={conversation_id}, role={role}")
        return message
    
    def commit_and_refresh_message(self, message: Message) -> Message:
        """
        Commit message ƒë√£ ƒë∆∞·ª£c prepare v√† refresh ƒë·ªÉ l·∫•y ID.
        Sau ƒë√≥ invalidate caches.
        
        Args:
            message: Message object ƒë√£ ƒë∆∞·ª£c prepare
            
        Returns:
            Message object ƒë√£ commit v√† refresh
        """
        self.db.commit()
        self.db.refresh(message)
        
        # Invalidate caches sau khi commit
        self._rebuild_messages_cache(message.conversation_id)
        self._sync_related_caches(message.conversation_id)
        
        # Invalidate cache t√≥m t·∫Øt v√¨ c√≥ tin nh·∫Øn m·ªõi
        summary_cache_key = CacheService._get_cache_key(
            CacheService.CONVERSATION_METADATA, 
            conversation_id=f"{message.conversation_id}_latest_summary"
        )
        CacheService.delete_cache(summary_cache_key)
        
        logger.debug(f"‚úÖ Committed and refreshed message_id={message.message_id}")
        return message
    
    def add_message_immediate(self, conversation_id: int, role: str, content: str) -> Message:
        """
        Version kh√¥ng thay ƒë·ªïi c·ªßa add_message - commit ngay l·∫≠p t·ª©c.
        D√πng cho tr∆∞·ªùng h·ª£p c·∫ßn response ngay (nh∆∞ user message tr∆∞·ªõc khi g·ªçi LLM).
        """
        message = self.prepare_add_message(conversation_id, role, content)
        return self.commit_and_refresh_message(message)
    
    def prepare_health_data(self, conversation_id: int, user_id: int, 
                           health_condition: str = None, medical_history: str = None,
                           allergies: str = None, dietary_habits: str = None,
                           health_goals: str = None, additional_info: Dict = None,
                           data: Dict = None) -> Optional[HealthData]:
        """
        Chu·∫©n b·ªã HealthData object m√† kh√¥ng commit v√†o DB ngay.
        D√πng cho background processing.
        """
        try:
            existing_health_data = self.db.query(HealthData).filter(
                HealthData.conversation_id == conversation_id,
                HealthData.user_id == user_id
            ).first()

            if existing_health_data:
                # Update existing
                def update_field_safely(field_name: str, new_value: str, current_value: str) -> str:
                    if not new_value or new_value.strip() == "":
                        return current_value
                    if not current_value or current_value.strip() == "":
                        return new_value
                    if new_value not in current_value:
                        return f"{current_value}. {new_value}"
                    return current_value

                if health_condition:
                    existing_health_data.health_condition = update_field_safely(
                        "health_condition", health_condition, existing_health_data.health_condition or ""
                    )
                if medical_history:
                    existing_health_data.medical_history = update_field_safely(
                        "medical_history", medical_history, existing_health_data.medical_history or ""
                    )
                if allergies:
                    existing_health_data.allergies = update_field_safely(
                        "allergies", allergies, existing_health_data.allergies or ""
                    )
                if dietary_habits:
                    existing_health_data.dietary_habits = update_field_safely(
                        "dietary_habits", dietary_habits, existing_health_data.dietary_habits or ""
                    )
                if health_goals:
                    existing_health_data.health_goals = update_field_safely(
                        "health_goals", health_goals, existing_health_data.health_goals or ""
                    )

                if additional_info:
                    current_additional = existing_health_data.additional_info or {}
                    if isinstance(current_additional, str):
                        try:
                            current_additional = json.loads(current_additional)
                        except:
                            current_additional = {}
                    current_additional.update(additional_info)
                    existing_health_data.additional_info = current_additional

                if data:
                    current_data = existing_health_data.data or {}
                    if isinstance(current_data, str):
                        try:
                            current_data = json.loads(current_data)
                        except:
                            current_data = {}
                    current_data.update(data)
                    existing_health_data.data = current_data

                existing_health_data.updated_at = datetime.now()
                logger.debug(f"üìù Prepared update health_data for conversation_id={conversation_id}")
                return existing_health_data
            else:
                # Create new
                health_data = HealthData(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    health_condition=health_condition,
                    medical_history=medical_history,
                    allergies=allergies,
                    dietary_habits=dietary_habits,
                    health_goals=health_goals,
                    additional_info=additional_info,
                    data=data
                )
                self.db.add(health_data)
                logger.debug(f"üìù Prepared create new health_data for conversation_id={conversation_id}")
                return health_data

        except Exception as e:
            logger.error(f"üí• L·ªói khi prepare health_data: {str(e)}")
            return None
    
    def commit_and_refresh_health_data(self, health_data: HealthData) -> HealthData:
        """
        Commit health_data ƒë√£ ƒë∆∞·ª£c prepare v√† refresh ƒë·ªÉ l·∫•y ID.
        Sau ƒë√≥ invalidate caches.
        """
        self.db.commit()
        self.db.refresh(health_data)
        
        # Invalidate health data cache
        health_cache_key = CacheService._get_cache_key(
            CacheService.HEALTH_DATA, 
            conversation_id=health_data.conversation_id
        )
        CacheService.delete_cache(health_cache_key)
        
        logger.debug(f"‚úÖ Committed and refreshed health_data id={health_data.id}")
        return health_data 