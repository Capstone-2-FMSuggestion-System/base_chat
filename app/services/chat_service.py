import logging
from sqlalchemy.orm import Session
from typing import Dict, List, Optional, Any, Union, Tuple
from fastapi import HTTPException
import asyncio
from datetime import datetime
from sqlalchemy import desc

from app.repositories.chat_repository import ChatRepository
from app.services.llm_service_factory import LLMServiceFactory
from app.services.gemini_prompt_service import GeminiPromptService
from app.services.chat_flow import run_chat_flow
from app.services.background_db_service import background_db_service
from app.services.product_service import ProductService
from app.config import settings
from app.db.models import Message
from app.schemas.chat import ChatResponse, NewChatResponse


logger = logging.getLogger(__name__)


class ChatService:
    """
    ChatService - Ki·∫øn tr√∫c s∆∞ H·ªá th·ªëng Chatbot
    
    Ch·ªãu tr√°ch nhi·ªám ƒëi·ªÅu ph·ªëi to√†n b·ªô quy tr√¨nh x·ª≠ l√Ω tin nh·∫Øn,
    bao g·ªìm t·∫°o v√† l∆∞u tr·ªØ t√≥m t·∫Øt tƒÉng d·∫ßn sau m·ªói l∆∞·ª£t t∆∞∆°ng t√°c.
    """
    
    def __init__(self, db: Session):
        self.db = db
        self.repository = ChatRepository(db)
        self.llm_service = LLMServiceFactory(
            service_type=settings.LLM_SERVICE_TYPE,
            llama_url=settings.LLAMA_CPP_URL,
            ollama_url=settings.OLLAMA_URL
        )
        self.gemini_service = GeminiPromptService()
        self.product_service = ProductService()
        self.medichat_model = "medichat-llama3:8b_q4_K_M"  # Model Medichat t·ª´ Ollama
    
    async def process_message(self, user_id: int, message_content: str, conversation_id: Optional[int] = None) -> Dict[str, Any]:
        """
        ƒêi·ªÅu ph·ªëi quy tr√¨nh x·ª≠ l√Ω tin nh·∫Øn v·ªõi t√≥m t·∫Øt tƒÉng d·∫ßn.
        
        Flow:
        1. Chu·∫©n b·ªã conversation v√† l·∫•y l·ªãch s·ª≠ chat
        2. G·ªçi run_chat_flow (LangGraph) ƒë·ªÉ x·ª≠ l√Ω logic ch√≠nh
        3. Ki·ªÉm tra ƒëi·ªÅu ki·ªán v√† t·∫°o t√≥m t·∫Øt tƒÉng d·∫ßn
        4. L∆∞u t√≥m t·∫Øt v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ ho√†n ch·ªânh
        
        Args:
            user_id: ID ng∆∞·ªùi d√πng
            message_content: N·ªôi dung tin nh·∫Øn
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán (optional)
            
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ x·ª≠ l√Ω v√† t√≥m t·∫Øt hi·ªán t·∫°i
        """
        # B∆∞·ªõc 1: Chu·∫©n b·ªã conversation
        if not conversation_id:
            conversation = self.repository.get_latest_conversation(user_id)
            if not conversation:
                # T·∫°o conversation m·ªõi v√† tr·∫£ v·ªÅ v·ªõi welcome message
                return await self._handle_new_conversation(user_id, message_content)
            conversation_id = conversation.conversation_id
        else:
            conversation = self.repository.get_conversation_by_id(conversation_id)
            if not conversation or conversation.user_id != user_id:
                raise ValueError("Cu·ªôc tr√≤ chuy·ªán kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng c√≥ quy·ªÅn truy c·∫≠p.")

        # B∆∞·ªõc 2: L·∫•y l·ªãch s·ª≠ chat TR∆Ø·ªöC khi tin nh·∫Øn hi·ªán t·∫°i ƒë∆∞·ª£c th√™m
        chat_history_before_current_message = self.repository.get_messages(conversation_id)
        logger.info(f"üîÑ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω tin nh·∫Øn cho conversation_id={conversation_id}, user_id={user_id}")

        try:
            # B∆∞·ªõc 3: G·ªçi LangGraph ƒë·ªÉ x·ª≠ l√Ω logic ch√≠nh
            langgraph_result = await run_chat_flow(
                user_message=message_content,
                user_id=user_id,
                conversation_id=conversation_id,
                messages=chat_history_before_current_message,
                repository=self.repository,
                llm_service=self.llm_service
            )
            
            # B∆∞·ªõc 4: X·ª≠ l√Ω s·∫£n ph·∫©m c√≥ s·∫µn n·∫øu c√≥ menu ƒë∆∞·ª£c t·∫°o
            await self._handle_available_products(langgraph_result)
            
            # B∆∞·ªõc 5: X·ª≠ l√Ω t√≥m t·∫Øt tƒÉng d·∫ßn
            current_summary = await self._handle_incremental_summary(
                conversation_id=conversation_id,
                message_content=message_content,
                langgraph_result=langgraph_result
            )
            
            # B∆∞·ªõc 6: Chu·∫©n b·ªã v√† tr·∫£ v·ªÅ response
            response_payload = self._build_response_payload(
                conversation_id=conversation_id,
                message_content=message_content,
                langgraph_result=langgraph_result,
                current_summary=current_summary
            )
            
            logger.info(f"‚úÖ X·ª≠ l√Ω th√†nh c√¥ng tin nh·∫Øn cho conversation_id={conversation_id}")
            return response_payload
            
        except Exception as e:
            logger.error(f"üí• L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω tin nh·∫Øn (ChatService): {str(e)}", exc_info=True)
            return await self._handle_error_response(conversation_id, message_content, e)

    async def _handle_available_products(self, langgraph_result: Dict[str, Any]) -> None:
        """
        X·ª≠ l√Ω vi·ªác l·∫•y th√¥ng tin s·∫£n ph·∫©m c√≥ s·∫µn sau khi l∆∞u menu.
        
        Args:
            langgraph_result: K·∫øt qu·∫£ t·ª´ LangGraph ch·ª©a th√¥ng tin menu ƒë√£ t·∫°o
        """
        try:
            # Ki·ªÉm tra xem c√≥ menu_ids ƒë∆∞·ª£c t·∫°o kh√¥ng
            menu_ids = langgraph_result.get("menu_ids", [])
            if not menu_ids:
                logger.debug("Kh√¥ng c√≥ menu n√†o ƒë∆∞·ª£c t·∫°o, b·ªè qua vi·ªác l·∫•y s·∫£n ph·∫©m")
                return
            
            logger.info(f"üõí B·∫Øt ƒë·∫ßu l·∫•y s·∫£n ph·∫©m c√≥ s·∫µn cho {len(menu_ids)} menu")
            
            # Danh s√°ch t·∫•t c·∫£ s·∫£n ph·∫©m c√≥ s·∫µn t·ª´ t·∫•t c·∫£ menu
            all_available_products = []
            processed_product_ids = set()  # Tr√°nh tr√πng l·∫∑p s·∫£n ph·∫©m
            
            # X·ª≠ l√Ω t·ª´ng menu
            for menu_id in menu_ids:
                try:
                    # L·∫•y th√¥ng tin recipe t·ª´ repository
                    recipe_data = self.repository.get_recipe_by_id(menu_id)
                    if not recipe_data:
                        logger.warning(f"Kh√¥ng t√¨m th·∫•y recipe v·ªõi menu_id={menu_id}")
                        continue
                    
                    # L·∫•y danh s√°ch ingredients c√≥ product_id
                    ingredients = recipe_data.get('ingredients', [])
                    logger.debug(f"üìã Menu {menu_id} c√≥ {len(ingredients)} ingredients")
                    
                    # L·∫•y s·∫£n ph·∫©m c√≥ s·∫µn cho menu n√†y
                    available_products = await self.product_service.get_available_products_from_menu_items(ingredients)
                    
                    if available_products:
                        # L·ªçc ra s·∫£n ph·∫©m ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω (tr√°nh tr√πng l·∫∑p)
                        new_products = []
                        for product in available_products:
                            product_id = product.get('id')
                            if product_id and product_id not in processed_product_ids:
                                new_products.append(product)
                                processed_product_ids.add(product_id)
                        
                        all_available_products.extend(new_products)
                        
                        # C·∫≠p nh·∫≠t cache cho recipe n√†y
                        recipe_data['available_products'] = available_products
                        from app.services.cache_service import CacheService
                        CacheService.cache_recipe_data(menu_id, recipe_data)
                        
                        logger.info(f"‚úÖ Menu {menu_id}: Th√™m {len(new_products)} s·∫£n ph·∫©m m·ªõi ({len(available_products)} total)")
                    else:
                        logger.debug(f"‚ùå Menu {menu_id}: Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o c√≥ s·∫µn")
                        
                except Exception as e:
                    logger.error(f"üí• L·ªói khi x·ª≠ l√Ω s·∫£n ph·∫©m cho menu_id={menu_id}: {str(e)}")
                    continue
            
            # Th√™m t·∫•t c·∫£ s·∫£n ph·∫©m c√≥ s·∫µn v√†o langgraph_result
            if all_available_products:
                langgraph_result['available_products'] = all_available_products
                logger.info(f"üéØ T·ªïng c·ªông: {len(all_available_products)} s·∫£n ph·∫©m c√≥ s·∫µn ƒë∆∞·ª£c th√™m v√†o response")
                
                # Log chi ti·∫øt c√°c s·∫£n ph·∫©m
                for product in all_available_products:
                    logger.debug(f"üõçÔ∏è Available product: {product.get('name')} (ID: {product.get('id')}) - Stock: {product.get('stock_quantity')}")
            else:
                logger.info("‚ÑπÔ∏è Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o c√≥ s·∫µn trong kho cho c√°c menu ƒë∆∞·ª£c t·∫°o")
                langgraph_result['available_products'] = []
                    
        except Exception as e:
            logger.error(f"üí• L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω s·∫£n ph·∫©m c√≥ s·∫µn: {str(e)}", exc_info=True)
            # ƒê·∫£m b·∫£o lu√¥n c√≥ key n√†y trong response
            langgraph_result['available_products'] = []

    async def _handle_new_conversation(self, user_id: int, message_content: str) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω tin nh·∫Øn ƒë·∫ßu ti√™n trong conversation m·ªõi.
        
        Returns:
            Dict v·ªõi conversation_id m·ªõi v√† welcome message
        """
        try:
            conversation = self.repository.create_conversation(user_id)
            conversation_id = conversation.conversation_id
            
            # T·∫°o welcome message
            welcome_message_content = await self.gemini_service.generate_welcome_message()
            self.repository.add_message(conversation_id, "assistant", welcome_message_content)
            
            # Th√™m tin nh·∫Øn user
            self.repository.add_message(conversation_id, "user", message_content)
            
            logger.info(f"üÜï T·∫°o conversation m·ªõi: {conversation_id} cho user_id={user_id}")
            
            return {
                "conversation_id": conversation_id,
                "user_message": {"role": "user", "content": message_content},
                "assistant_message": {"role": "assistant", "content": welcome_message_content},
                "current_summary": None,
                "is_new_conversation": True
            }
            
        except Exception as e:
            logger.error(f"üí• L·ªói khi t·∫°o conversation m·ªõi: {str(e)}", exc_info=True)
            raise

    async def _handle_incremental_summary(self, conversation_id: int, message_content: str, langgraph_result: Dict[str, Any]) -> Optional[str]:
        """
        X·ª≠ l√Ω vi·ªác t·∫°o v√† l∆∞u t√≥m t·∫Øt tƒÉng d·∫ßn.
        
        Logic:
        - Ch·ªâ t·∫°o t√≥m t·∫Øt n·∫øu: is_valid_scope=True, need_more_info=False, c√≥ final_response
        - C·∫ßn c√≥ user_message_id_db v√† assistant_message_id_db t·ª´ LangGraph
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán
            message_content: N·ªôi dung tin nh·∫Øn user
            langgraph_result: K·∫øt qu·∫£ t·ª´ LangGraph
            
        Returns:
            T√≥m t·∫Øt hi·ªán t·∫°i (m·ªõi ho·∫∑c c≈©)
        """
        # L·∫•y message IDs t·ª´ LangGraph result
        user_message_id = langgraph_result.get("user_message_id_db")
        assistant_message_id = langgraph_result.get("assistant_message_id_db")

        if not user_message_id or not assistant_message_id:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng nh·∫≠n ƒë∆∞·ª£c message IDs t·ª´ chat_flow (user: {user_message_id}, assistant: {assistant_message_id}) - b·ªè qua t·∫°o t√≥m t·∫Øt")
            return self.repository.get_latest_summary(conversation_id)

        # Ki·ªÉm tra ƒëi·ªÅu ki·ªán t·∫°o t√≥m t·∫Øt
        should_create_summary = (
            langgraph_result.get("is_valid_scope", False) and 
            not langgraph_result.get("need_more_info", True) and
            langgraph_result.get("final_response")
        )

        if not should_create_summary:
            logger.debug(f"üîç Kh√¥ng ƒë·ªß ƒëi·ªÅu ki·ªán t·∫°o t√≥m t·∫Øt cho conversation_id={conversation_id}")
            logger.debug(f"   - is_valid_scope: {langgraph_result.get('is_valid_scope')}")
            logger.debug(f"   - need_more_info: {langgraph_result.get('need_more_info')}")
            logger.debug(f"   - has_final_response: {bool(langgraph_result.get('final_response'))}")
            return self.repository.get_latest_summary(conversation_id)

        # T·∫°o t√≥m t·∫Øt tƒÉng d·∫ßn
        try:
            logger.info(f"üìù B·∫Øt ƒë·∫ßu t·∫°o t√≥m t·∫Øt tƒÉng d·∫ßn cho conversation_id={conversation_id}")
            
            # L·∫•y d·ªØ li·ªáu c·∫ßn thi·∫øt cho t√≥m t·∫Øt
            previous_summary_text = self.repository.get_latest_summary(conversation_id)
            summary_context_messages = self.repository.get_messages_for_summary_context(conversation_id, limit=3)
            final_response = langgraph_result.get("final_response", "")

            logger.debug(f"   - Previous summary: {'C√≥' if previous_summary_text else 'Kh√¥ng'} ({len(previous_summary_text or '')} k√Ω t·ª±)")
            logger.debug(f"   - Context messages: {len(summary_context_messages)} tin nh·∫Øn")
            logger.debug(f"   - Final response: {len(final_response)} k√Ω t·ª±")

            # G·ªçi Gemini ƒë·ªÉ t·∫°o t√≥m t·∫Øt
            new_summary_text = await self.gemini_service.create_incremental_summary(
                previous_summary=previous_summary_text,
                new_user_message=message_content,
                new_assistant_message=final_response,
                full_chat_history_for_context=summary_context_messages
            )

            if not new_summary_text:
                logger.warning(f"‚ö†Ô∏è Gemini tr·∫£ v·ªÅ summary r·ªóng cho conversation_id={conversation_id}")
                return previous_summary_text

            # L∆∞u t√≥m t·∫Øt v√†o DB
            save_success = self.repository.save_conversation_summary(
                conversation_id=conversation_id,
                assistant_message_id=assistant_message_id,
                summary_text=new_summary_text
            )

            if save_success:
                logger.info(f"üíæ ƒê√£ l∆∞u t√≥m t·∫Øt m·ªõi: {len(new_summary_text)} k√Ω t·ª± cho conversation_id={conversation_id}")
                return new_summary_text
            else:
                logger.error(f"‚ùå Kh√¥ng th·ªÉ l∆∞u t√≥m t·∫Øt cho conversation_id={conversation_id} - gi·ªØ nguy√™n t√≥m t·∫Øt c≈©")
                return previous_summary_text

        except Exception as e:
            logger.error(f"üí• L·ªói khi t·∫°o t√≥m t·∫Øt tƒÉng d·∫ßn cho conversation_id={conversation_id}: {str(e)}", exc_info=True)
            # Fallback: tr·∫£ v·ªÅ t√≥m t·∫Øt c≈© n·∫øu c√≥ l·ªói
            return self.repository.get_latest_summary(conversation_id)

    def _build_response_payload(self, conversation_id: int, message_content: str, langgraph_result: Dict[str, Any], current_summary: Optional[str]) -> Dict[str, Any]:
        """
        X√¢y d·ª±ng response payload ho√†n ch·ªânh.
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán
            message_content: N·ªôi dung tin nh·∫Øn user g·ªëc
            langgraph_result: K·∫øt qu·∫£ t·ª´ LangGraph
            current_summary: T√≥m t·∫Øt hi·ªán t·∫°i
            
        Returns:
            Dict response ho√†n ch·ªânh
        """
        response_payload = {
            "conversation_id": conversation_id,
            "user_message": langgraph_result.get("user_message", {"role": "user", "content": message_content}),
            "assistant_message": langgraph_result.get("assistant_message", {
                "role": "assistant", 
                "content": langgraph_result.get("final_response", "")
            }),
            "current_summary": current_summary
        }
        
        # Th√™m c√°c metadata t·ª´ LangGraph
        metadata_keys = [
            "is_valid_scope", "need_more_info", "is_food_related", 
            "user_rejected_info", "suggest_general_options", 
            "limit_reached", "message_count", "available_products"
        ]
        
        for key in metadata_keys:
            if key in langgraph_result:
                response_payload[key] = langgraph_result[key]
        
        return response_payload

    async def _handle_error_response(self, conversation_id: Optional[int], message_content: str, error: Exception) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω response khi c√≥ l·ªói nghi√™m tr·ªçng.
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán (c√≥ th·ªÉ None)
            message_content: N·ªôi dung tin nh·∫Øn user
            error: Exception ƒë√£ x·∫£y ra
            
        Returns:
            Dict error response an to√†n
        """
        error_response_content = "Xin l·ªói, h·ªá th·ªëng g·∫∑p l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i sau."
        
        # C·ªë g·∫Øng l∆∞u error message v√†o DB n·∫øu c√≥ conversation_id
        try:
            if conversation_id:
                self.repository.add_message(conversation_id, "assistant", error_response_content)
        except Exception as db_error:
            logger.error(f"üí• L·ªói khi l∆∞u error message v√†o DB: {db_error}")

        # L·∫•y t√≥m t·∫Øt c≈© nh·∫•t n·∫øu c√≥ th·ªÉ
        current_summary = None
        try:
            if conversation_id:
                current_summary = self.repository.get_latest_summary(conversation_id)
        except Exception as summary_error:
            logger.error(f"üí• Kh√¥ng th·ªÉ l·∫•y t√≥m t·∫Øt trong error handler: {summary_error}")

        return {
            "conversation_id": conversation_id,
            "user_message": {"role": "user", "content": message_content},
            "assistant_message": {"role": "assistant", "content": error_response_content},
            "current_summary": current_summary,
            "error": "L·ªói h·ªá th·ªëng - vui l√≤ng th·ª≠ l·∫°i",
            "error_details": str(error) if settings.DEBUG else None
        }

    def create_new_chat(self, user_id: int) -> Dict[str, Any]:
        """
        T·∫°o cu·ªôc tr√≤ chuy·ªán m·ªõi v·ªõi welcome message.
        
        Args:
            user_id: ID ng∆∞·ªùi d√πng
            
        Returns:
            Dict v·ªõi th√¥ng tin conversation m·ªõi
        """
        try:
            conversation = self.repository.create_conversation(user_id)
            conversation_id = conversation.conversation_id
            
            # T·∫°o welcome message
            try:
                welcome_message = asyncio.run(self.gemini_service.generate_welcome_message())
            except Exception as e:
                logger.error(f"üí• L·ªói khi t·∫°o welcome message v·ªõi Gemini: {str(e)}")
                welcome_message = "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω t∆∞ v·∫•n dinh d∆∞·ª°ng v√† s·ª©c kh·ªèe. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n h√¥m nay?"
            
            # L∆∞u welcome message
            self.repository.add_message(conversation_id, "assistant", welcome_message)
            
            logger.info(f"üÜï T·∫°o chat m·ªõi th√†nh c√¥ng: conversation_id={conversation_id}, user_id={user_id}")
            
            return {
                "conversation_id": conversation_id,
                "created_at": conversation.created_at.isoformat(),
                "welcome_message": welcome_message,
                "current_summary": None  # Chat m·ªõi ch∆∞a c√≥ t√≥m t·∫Øt
            }
            
        except Exception as e:
            logger.error(f"üí• L·ªói khi t·∫°o chat m·ªõi cho user_id={user_id}: {str(e)}", exc_info=True)
            raise HTTPException(status_code=500, detail="Kh√¥ng th·ªÉ t·∫°o cu·ªôc tr√≤ chuy·ªán m·ªõi")

    async def get_chat_content(self, user_id: int, conversation_id: Optional[int] = None) -> Dict[str, Any]:
        """
        L·∫•y n·ªôi dung cu·ªôc tr√≤ chuy·ªán bao g·ªìm t√≥m t·∫Øt hi·ªán t·∫°i v√† s·∫£n ph·∫©m c√≥ s·∫µn.
        
        Args:
            user_id: ID ng∆∞·ªùi d√πng
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán (optional - l·∫•y latest n·∫øu None)
            
        Returns:
            Dict v·ªõi messages, summary, health_data v√† available_products
        """
        try:
            # X√°c ƒë·ªãnh conversation
            if conversation_id:
                # Ki·ªÉm tra quy·ªÅn truy c·∫≠p
                if not self.repository.is_user_owner_of_conversation(user_id, conversation_id):
                    raise HTTPException(status_code=403, detail="Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p cu·ªôc tr√≤ chuy·ªán n√†y")
                
                conversation = self.repository.get_conversation_by_id(conversation_id)
                if not conversation:
                    raise HTTPException(status_code=404, detail="Cu·ªôc tr√≤ chuy·ªán kh√¥ng t·ªìn t·∫°i")
            else:
                # L·∫•y conversation g·∫ßn nh·∫•t
                conversation = self.repository.get_latest_conversation(user_id)
                if not conversation:
                    return {
                        "conversation_id": None,
                        "messages": [],
                        "current_summary": None,
                        "health_data": None,
                        "available_products": []
                    }

            # L·∫•y d·ªØ li·ªáu conversation
            messages_from_db = self.repository.get_messages(conversation.conversation_id)
            current_summary_text = self.repository.get_latest_summary(conversation.conversation_id)
            health_data_db = self.repository.get_health_data(conversation.conversation_id)
            
            # L·∫•y s·∫£n ph·∫©m c√≥ s·∫µn t·ª´ c√°c menu ƒë√£ ƒë∆∞·ª£c l∆∞u trong conversation
            available_products = await self._get_available_products_for_conversation(conversation.conversation_id)
            
            logger.debug(f"üìñ L·∫•y chat content: conversation_id={conversation.conversation_id}, messages={len(messages_from_db)}, summary={'C√≥' if current_summary_text else 'Kh√¥ng'}, products={len(available_products)}")
            
            result = {
                "conversation_id": conversation.conversation_id,
                "messages": messages_from_db,
                "current_summary": current_summary_text,
                "health_data": health_data_db if health_data_db else None,
                "available_products": available_products
            }
            
            return result
            
        except HTTPException:
            # Re-raise HTTPException ƒë·ªÉ FastAPI x·ª≠ l√Ω
            raise
        except Exception as e:
            logger.error(f"üí• L·ªói khi l·∫•y chat content cho user_id={user_id}, conversation_id={conversation_id}: {str(e)}", exc_info=True)
            raise HTTPException(status_code=500, detail="Kh√¥ng th·ªÉ l·∫•y n·ªôi dung cu·ªôc tr√≤ chuy·ªán")

    async def _get_available_products_for_conversation(self, conversation_id: int) -> List[Dict[str, Any]]:
        """
        L·∫•y danh s√°ch s·∫£n ph·∫©m c√≥ s·∫µn t·ª´ c√°c menu ƒë√£ ƒë∆∞·ª£c t·∫°o trong conversation.
        
        Args:
            conversation_id: ID cu·ªôc tr√≤ chuy·ªán
            
        Returns:
            List c√°c s·∫£n ph·∫©m c√≥ s·∫µn
        """
        try:
            # L·∫•y t·∫•t c·∫£ menu ƒë√£ ƒë∆∞·ª£c t·∫°o trong conversation n√†y
            menu_data_list = self.repository.get_menu_data_by_conversation(conversation_id)
            
            if not menu_data_list:
                logger.debug(f"üì≠ Kh√¥ng t√¨m th·∫•y menu n√†o cho conversation_id={conversation_id}")
                return []
            
            all_available_products = []
            processed_product_ids = set()
            
            for menu_data in menu_data_list:
                try:
                    menu_id = menu_data.get('menu_id')
                    if not menu_id:
                        continue
                    
                    # L·∫•y th√¥ng tin recipe t·ª´ repository
                    recipe_data = self.repository.get_recipe_by_id(menu_id)
                    if not recipe_data:
                        logger.warning(f"Kh√¥ng t√¨m th·∫•y recipe v·ªõi menu_id={menu_id}")
                        continue
                    
                    # L·∫•y danh s√°ch ingredients c√≥ product_id
                    ingredients = recipe_data.get('ingredients', [])
                    if not ingredients:
                        continue
                    
                    # L·∫•y s·∫£n ph·∫©m c√≥ s·∫µn cho menu n√†y
                    available_products = await self.product_service.get_available_products_from_menu_items(ingredients)
                    
                    if available_products:
                        # L·ªçc ra s·∫£n ph·∫©m ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω (tr√°nh tr√πng l·∫∑p)
                        for product in available_products:
                            product_id = product.get('id')
                            if product_id and product_id not in processed_product_ids:
                                all_available_products.append(product)
                                processed_product_ids.add(product_id)
                                
                        logger.debug(f"‚úÖ Menu {menu_id}: T√¨m th·∫•y {len(available_products)} s·∫£n ph·∫©m c√≥ s·∫µn")
                    
                except Exception as e:
                    logger.error(f"üí• L·ªói khi x·ª≠ l√Ω menu trong conversation: {str(e)}")
                    continue
            
            logger.info(f"üõí T·ªïng c·ªông: {len(all_available_products)} s·∫£n ph·∫©m c√≥ s·∫µn cho conversation_id={conversation_id}")
            return all_available_products
            
        except Exception as e:
            logger.error(f"üí• L·ªói khi l·∫•y s·∫£n ph·∫©m c√≥ s·∫µn cho conversation_id={conversation_id}: {str(e)}", exc_info=True)
            return []

    # === BACKGROUND DB OPERATIONS METHODS ===
    
    async def process_message_with_background(self, user_id: int, message_content: str, 
                                           conversation_id: Optional[int] = None) -> Tuple[Dict[str, Any], List[str]]:
        """
        Version c·ªßa process_message v·ªõi background DB operations.
        
        Returns:
            Tuple[response_data, background_task_ids]
        """
        background_task_ids = []
        
        # B∆∞·ªõc 1: Chu·∫©n b·ªã conversation
        if not conversation_id:
            conversation = self.repository.get_latest_conversation(user_id)
            if not conversation:
                # T·∫°o conversation m·ªõi v√† tr·∫£ v·ªÅ v·ªõi welcome message
                return await self._handle_new_conversation_with_background(user_id, message_content)
            conversation_id = conversation.conversation_id
        else:
            conversation = self.repository.get_conversation_by_id(conversation_id)
            if not conversation or conversation.user_id != user_id:
                raise ValueError("Cu·ªôc tr√≤ chuy·ªán kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng c√≥ quy·ªÅn truy c·∫≠p.")

        # B∆∞·ªõc 2: L·∫•y l·ªãch s·ª≠ chat TR∆Ø·ªöC khi tin nh·∫Øn hi·ªán t·∫°i ƒë∆∞·ª£c th√™m
        chat_history_before_current_message = self.repository.get_messages(conversation_id)
        logger.info(f"üîÑ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω tin nh·∫Øn v·ªõi background DB cho conversation_id={conversation_id}, user_id={user_id}")

        try:
            # B∆∞·ªõc 3: G·ªçi LangGraph ƒë·ªÉ x·ª≠ l√Ω logic ch√≠nh
            langgraph_result = await run_chat_flow(
                user_message=message_content,
                user_id=user_id,
                conversation_id=conversation_id,
                messages=chat_history_before_current_message,
                repository=self.repository,
                llm_service=self.llm_service
            )
            
            # B∆∞·ªõc 4: Chu·∫©n b·ªã background tasks cho DB operations
            background_task_ids.extend(
                await self._prepare_background_db_tasks(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message_content=message_content,
                    langgraph_result=langgraph_result
                )
            )
            
            # B∆∞·ªõc 5: Chu·∫©n b·ªã response (kh√¥ng ch·ªù DB commit)
            current_summary = self.repository.get_latest_summary(conversation_id)
            response_payload = self._build_response_payload(
                conversation_id=conversation_id,
                message_content=message_content,
                langgraph_result=langgraph_result,
                current_summary=current_summary
            )
            
            logger.info(f"‚úÖ X·ª≠ l√Ω th√†nh c√¥ng tin nh·∫Øn v·ªõi {len(background_task_ids)} background tasks cho conversation_id={conversation_id}")
            return response_payload, background_task_ids
            
        except Exception as e:
            logger.error(f"üí• L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω tin nh·∫Øn v·ªõi background (ChatService): {str(e)}", exc_info=True)
            error_response = await self._handle_error_response(conversation_id, message_content, e)
            return error_response, background_task_ids

    async def _handle_new_conversation_with_background(self, user_id: int, message_content: str) -> Tuple[Dict[str, Any], List[str]]:
        """
        X·ª≠ l√Ω tin nh·∫Øn ƒë·∫ßu ti√™n trong conversation m·ªõi v·ªõi background operations.
        """
        try:
            conversation = self.repository.create_conversation(user_id)
            conversation_id = conversation.conversation_id
            
            # T·∫°o welcome message
            welcome_message_content = await self.gemini_service.generate_welcome_message()
            
            # T·∫°o background tasks cho messages
            task_ids = []
            
            # Task cho welcome message
            welcome_task_id = background_db_service.add_message_task(
                conversation_id=conversation_id,
                role="assistant",
                content=welcome_message_content,
                repository_instance=self.repository
            )
            task_ids.append(welcome_task_id)
            
            # Task cho user message
            user_task_id = background_db_service.add_message_task(
                conversation_id=conversation_id,
                role="user", 
                content=message_content,
                repository_instance=self.repository
            )
            task_ids.append(user_task_id)
            
            logger.info(f"üÜï T·∫°o conversation m·ªõi v·ªõi background tasks: {conversation_id} cho user_id={user_id}")
            
            response_data = {
                "conversation_id": conversation_id,
                "user_message": {"role": "user", "content": message_content},
                "assistant_message": {"role": "assistant", "content": welcome_message_content},
                "current_summary": None,
                "is_new_conversation": True
            }
            
            return response_data, task_ids
            
        except Exception as e:
            logger.error(f"üí• L·ªói khi t·∫°o conversation m·ªõi v·ªõi background: {str(e)}", exc_info=True)
            raise

    async def _prepare_background_db_tasks(self, conversation_id: int, user_id: int,
                                         message_content: str, langgraph_result: Dict[str, Any]) -> List[str]:
        """
        Chu·∫©n b·ªã c√°c background DB tasks d·ª±a tr√™n k·∫øt qu·∫£ t·ª´ LangGraph.
        
        Returns:
            List task IDs ƒë√£ ƒë∆∞·ª£c t·∫°o
        """
        task_ids = []
        
        try:
            # Task 1: Save user message n·∫øu ch∆∞a c√≥
            user_message_id = langgraph_result.get("user_message_id_db")
            if not user_message_id:
                user_task_id = background_db_service.add_message_task(
                    conversation_id=conversation_id,
                    role="user",
                    content=message_content,
                    repository_instance=self.repository
                )
                task_ids.append(user_task_id)
                logger.debug(f"üìù T·∫°o background task cho user message: {user_task_id}")
            
            # Task 2: Save assistant message n·∫øu c√≥ final_response
            final_response = langgraph_result.get("final_response")
            assistant_message_id = langgraph_result.get("assistant_message_id_db")
            
            if final_response and not assistant_message_id:
                assistant_task_id = background_db_service.add_message_task(
                    conversation_id=conversation_id,
                    role="assistant",
                    content=final_response,
                    repository_instance=self.repository
                )
                task_ids.append(assistant_task_id)
                logger.debug(f"üìù T·∫°o background task cho assistant message: {assistant_task_id}")
            
            # Task 3: Save conversation summary n·∫øu ƒë·ªß ƒëi·ªÅu ki·ªán
            should_create_summary = (
                langgraph_result.get("is_valid_scope", False) and 
                not langgraph_result.get("need_more_info", True) and
                final_response and assistant_message_id
            )
            
            if should_create_summary:
                # T·∫°o summary v·ªõi Gemini
                previous_summary = self.repository.get_latest_summary(conversation_id)
                summary_context_messages = self.repository.get_messages_for_summary_context(conversation_id, limit=3)
                
                new_summary = await self.gemini_service.create_incremental_summary(
                    previous_summary=previous_summary,
                    new_user_message=message_content,
                    new_assistant_message=final_response,
                    full_chat_history_for_context=summary_context_messages
                )
                
                if new_summary:
                    summary_task_id = background_db_service.save_conversation_summary_task(
                        conversation_id=conversation_id,
                        assistant_message_id=assistant_message_id,
                        summary_text=new_summary,
                        repository_instance=self.repository
                    )
                    task_ids.append(summary_task_id)
                    logger.debug(f"üìù T·∫°o background task cho conversation summary: {summary_task_id}")
            
            # Task 4: Save health data n·∫øu c√≥
            extracted_health_data = langgraph_result.get("extracted_health_data")
            if extracted_health_data:
                health_task_id = background_db_service.save_health_data_task(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    health_data=extracted_health_data,
                    repository_instance=self.repository
                )
                task_ids.append(health_task_id)
                logger.debug(f"üìù T·∫°o background task cho health data: {health_task_id}")
            
            logger.info(f"üîÑ ƒê√£ chu·∫©n b·ªã {len(task_ids)} background DB tasks cho conversation_id={conversation_id}")
            return task_ids
            
        except Exception as e:
            logger.error(f"üí• L·ªói khi chu·∫©n b·ªã background DB tasks: {str(e)}", exc_info=True)
            return task_ids

    def execute_background_tasks(self, task_ids: List[str]) -> None:
        """
        Execute c√°c background DB tasks.
        ƒê∆∞·ª£c g·ªçi t·ª´ FastAPI BackgroundTasks.
        """
        if not task_ids:
            return
            
        logger.info(f"üöÄ B·∫Øt ƒë·∫ßu execute {len(task_ids)} background DB tasks")
        background_db_service.execute_multiple_tasks(task_ids)
        
    def get_background_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """
        L·∫•y tr·∫°ng th√°i c·ªßa m·ªôt background task.
        D√πng cho monitoring/debugging.
        """
        return background_db_service.get_task_status(task_id) 