import logging
from typing import Dict, List, Any, Optional, TypedDict, Annotated, Callable, Literal, Union
from langchain_core.messages import HumanMessage, AIMessage
from pydantic import BaseModel, Field
import json
from datetime import datetime
import asyncio
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from app.config import settings
from app.services.gemini_prompt_service import GeminiPromptService
from app.repositories.chat_repository import ChatRepository
from app.services.llm_service_factory import LLMServiceFactory
from app.services.cache_service import CacheService
from app.db.models import Message, HealthData

logger = logging.getLogger(__name__)

# Import cÃ¡c tool cáº§n thiáº¿t
from app.tools.recipe_tool import search_and_filter_recipes
from app.tools.product_find_tool import process_user_request_async
from app.tools.product_beverage import fetch_and_filter_drinks_in_batches_async, init_services

# Äá»‹nh nghÄ©a tráº¡ng thÃ¡i vá»›i Ä‘áº§y Ä‘á»§ cÃ¡c trÆ°á»ng cáº§n thiáº¿t
class ChatState(TypedDict):
    # ThÃ´ng tin cÆ¡ báº£n vá» cuá»™c trÃ² chuyá»‡n vÃ  ngÆ°á»i dÃ¹ng
    conversation_id: int
    user_id: int
    user_message: str  # Tin nháº¯n hiá»‡n táº¡i cá»§a ngÆ°á»i dÃ¹ng

    # Lá»‹ch sá»­ tin nháº¯n (cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ tÃ¡i táº¡o ngá»¯ cáº£nh náº¿u cáº§n)
    messages: List[Dict[str, str]]

    # Cá» vÃ  thÃ´ng tin tá»« bÆ°á»›c phÃ¢n tÃ­ch (check_scope_node)
    is_valid_scope: bool  # Tin nháº¯n cÃ³ náº±m trong pháº¡m vi há»— trá»£ khÃ´ng?
    is_greeting: bool     # Tin nháº¯n cÃ³ pháº£i lÃ  lá»i chÃ o há»i khÃ´ng?
    is_food_related: bool # Tin nháº¯n cÃ³ liÃªn quan Ä‘áº¿n mÃ³n Äƒn/Ä‘á»“ uá»‘ng khÃ´ng?

    user_rejected_info: bool # NgÆ°á»i dÃ¹ng cÃ³ tá»« chá»‘i cung cáº¥p thÃªm thÃ´ng tin khÃ´ng?
    need_more_info: bool     # CÃ³ cáº§n há»i thÃªm thÃ´ng tin tá»« ngÆ°á»i dÃ¹ng khÃ´ng?
    suggest_general_options: bool # CÃ³ nÃªn gá»£i Ã½ cÃ¡c lá»±a chá»n chung chung khÃ´ng (do thiáº¿u thÃ´ng tin/tá»« chá»‘i)?
    
    follow_up_question: Optional[str] # CÃ¢u há»i tiáº¿p theo náº¿u need_more_info lÃ  true

    collected_info: Dict[str, Any] # ThÃ´ng tin sá»©c khá»e, sá»Ÿ thÃ­ch Ä‘Ã£ thu tháº­p Ä‘Æ°á»£c tá»« ngÆ°á»i dÃ¹ng

    # ThÃ´ng tin liÃªn quan Ä‘áº¿n viá»‡c gá»i mÃ´ hÃ¬nh LLM (Medichat/LLaMA3)
    medichat_prompt: Optional[str]    # Prompt Ä‘Ã£ Ä‘Æ°á»£c táº¡o Ä‘á»ƒ gá»­i cho Medichat
    medichat_response: Optional[str]  # Pháº£n há»“i thÃ´ tá»« Medichat

    # Káº¿t quáº£ tá»« cÃ¡c tool (náº¿u cÃ³)
    recipe_results: Optional[List[Dict[str, Any]]] # Káº¿t quáº£ tá»« recipe_tool
    beverage_results: Optional[List[Dict[str, Any]]] # Káº¿t quáº£ tá»« product_beverage
    product_results: Optional[Dict[str, Any]]    # Káº¿t quáº£ tá»« product_find_tool
    
    # CÃ¡c cá» phÃ¢n loáº¡i yÃªu cáº§u (tá»« Nhiá»‡m vá»¥ E.1)
    requests_food: Optional[bool] # YÃªu cáº§u cá»¥ thá»ƒ vá» mÃ³n Äƒn
    requests_beverage: Optional[bool] # YÃªu cáº§u cá»¥ thá»ƒ vá» Ä‘á»“ uá»‘ng

    # Pháº£n há»“i cuá»‘i cÃ¹ng vÃ  lá»—i
    final_response: Optional[str] # Pháº£n há»“i cuá»‘i cÃ¹ng sáº½ Ä‘Æ°á»£c gá»­i cho ngÆ°á»i dÃ¹ng
    error: Optional[str]          # ThÃ´ng bÃ¡o lá»—i náº¿u cÃ³ sá»± cá»‘ xáº£y ra trong quÃ¡ trÃ¬nh xá»­ lÃ½
    
    # ID cá»§a tin nháº¯n trong database (Ä‘á»ƒ ChatService cÃ³ thá»ƒ truy cáº­p)
    user_message_id_db: Optional[int] # ID cá»§a tin nháº¯n ngÆ°á»i dÃ¹ng trong DB
    assistant_message_id_db: Optional[int] # ID cá»§a tin nháº¯n trá»£ lÃ½ trong DB

# CÃ¡c node xá»­ lÃ½
async def check_scope_node(state: ChatState) -> ChatState:
    """
    Kiá»ƒm tra xem ná»™i dung tin nháº¯n cÃ³ thuá»™c pháº¡m vi há»— trá»£ khÃ´ng.
    Cáº­p nháº­t state vá»›i Ä‘áº§y Ä‘á»§ cÃ¡c cá» tá»« analyze_query vÃ  logic xá»­ lÃ½ need_more_info.
    """
    logger.info(f"ğŸ” Äang kiá»ƒm tra pháº¡m vi ná»™i dung: {state['user_message'][:50]}...")
    
    try:
        # Táº¡o dá»‹ch vá»¥ Gemini
        gemini_service = GeminiPromptService()
        
        # Kiá»ƒm tra xem cÃ³ pháº£i tin nháº¯n chÃ o há»i khÃ´ng - váº«n giá»¯ xá»­ lÃ½ cÆ¡ báº£n nÃ y
        greeting_words = ["chÃ o", "hello", "hi", "xin chÃ o", "hey", "good morning", "good afternoon", "good evening"]
        is_greeting = any(word in state['user_message'].lower() for word in greeting_words)
        state['is_greeting'] = is_greeting
        
        if is_greeting:
            # Xá»­ lÃ½ tin nháº¯n chÃ o há»i Ä‘áº·c biá»‡t
            state['is_valid_scope'] = True
            state['is_food_related'] = False
            state['need_more_info'] = False
            state['user_rejected_info'] = False # KhÃ´ng tá»« chá»‘i khi chÃ o
            state['suggest_general_options'] = False
            state['follow_up_question'] = None
            greeting_response = await gemini_service.get_greeting_response(state['user_message'])
            state['final_response'] = greeting_response # Sáº½ Ä‘Æ°á»£c gÃ¡n vÃ o assistant_message á»Ÿ cleanup
            logger.info(f"âœ… ÄÃ£ xÃ¡c Ä‘á»‹nh lÃ  tin nháº¯n chÃ o há»i, pháº£n há»“i: {greeting_response[:50]}...")
            return state
            
        # Äáº£m báº£o messages cÃ³ tin nháº¯n hiá»‡n táº¡i
        current_messages = state['messages'].copy()
        
        # ThÃªm tin nháº¯n hiá»‡n táº¡i náº¿u chÆ°a cÃ³
        current_user_message_exists = False
        for msg in current_messages:
            if msg["role"] == "user" and msg["content"] == state['user_message']:
                current_user_message_exists = True
                break
                
        if not current_user_message_exists:
            current_messages.append({"role": "user", "content": state['user_message']})
        
        # PhÃ¢n tÃ­ch ná»™i dung tá»« Gemini dá»±a vÃ o TOÃ€N Bá»˜ lá»‹ch sá»­ trÃ² chuyá»‡n
        analysis = await gemini_service.analyze_query(state['user_message'], current_messages)
        
        # Cáº­p nháº­t tráº¡ng thÃ¡i tá»« phÃ¢n tÃ­ch cá»§a Gemini
        state['is_valid_scope'] = analysis.get('is_valid_scope', True)
        state['is_food_related'] = analysis.get('is_food_related', False)
        state['user_rejected_info'] = analysis.get('user_rejected_info', False)
        state['suggest_general_options'] = analysis.get('suggest_general_options', False)
        
        # â­ CÃC Cá»œ Má»šI Tá»ª NHIá»†M Vá»¤ E.1: PhÃ¢n loáº¡i mÃ³n Äƒn vÃ  Ä‘á»“ uá»‘ng
        state['requests_food'] = analysis.get('requests_food', False)
        state['requests_beverage'] = analysis.get('requests_beverage', False)
        
        # â­ LOGIC QUAN TRá»ŒNG: Xá»­ lÃ½ need_more_info dá»±a trÃªn user_rejected_info vÃ  suggest_general_options
        if state['user_rejected_info'] or state['suggest_general_options']:
            state['need_more_info'] = False
            state['follow_up_question'] = None
            logger.info(f"ğŸ¯ User tá»« chá»‘i hoáº·c cáº§n gá»£i Ã½ chung â†’ need_more_info = False")
        else:
            state['need_more_info'] = analysis.get('need_more_info', False)
            state['follow_up_question'] = analysis.get('follow_up_question')
        
        # Láº¥y thÃ´ng tin sá»©c khá»e tá»« phÃ¢n tÃ­ch cá»§a Gemini - khÃ´ng tá»± xá»­ lÃ½ tá»« khÃ³a ná»¯a
        collected_info = analysis.get('collected_info', {})
        
        # Lá»c bá» cÃ¡c giÃ¡ trá»‹ rá»—ng tá»« collected_info
        collected_info = {k: v for k, v in collected_info.items() if v}
        state['collected_info'] = collected_info
        
        logger.info(f"âœ… Káº¿t quáº£ phÃ¢n tÃ­ch scope:")
        logger.info(f"   - is_valid_scope: {state['is_valid_scope']}")
        logger.info(f"   - is_food_related: {state['is_food_related']}")
        logger.info(f"   - user_rejected_info: {state['user_rejected_info']}")
        logger.info(f"   - suggest_general_options: {state['suggest_general_options']}")
        logger.info(f"   - need_more_info: {state['need_more_info']}")
        logger.info(f"   - requests_food: {state['requests_food']}")
        logger.info(f"   - requests_beverage: {state['requests_beverage']}")
        
        # LÆ°u thÃ´ng tin sá»©c khá»e vÃ o Redis náº¿u cÃ³ vÃ  thuá»™c pháº¡m vi há»£p lá»‡
        if state['is_valid_scope'] and collected_info:
            await save_health_data_to_cache(
                state['conversation_id'], 
                state['user_id'],
                collected_info
            )
            logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u thÃ´ng tin sá»©c khá»e vÃ o cache: session:{state['conversation_id']}:health_info")
            
    except Exception as e:
        logger.error(f"ğŸ’¥ Lá»—i khi kiá»ƒm tra pháº¡m vi: {str(e)}", exc_info=True)
        state['error'] = f"Lá»—i khi kiá»ƒm tra pháº¡m vi: {str(e)}"
        state['is_valid_scope'] = True  # Fallback cho phÃ©p tiáº¿p tá»¥c
        state['is_food_related'] = False
        state['need_more_info'] = False
        state['user_rejected_info'] = False
        state['suggest_general_options'] = False
    
    return state

def persist_user_interaction_node_wrapper(state: ChatState, repository) -> ChatState:
    """
    â­ NODE Má»šI: LuÃ´n lÆ°u user_message vÃ  cáº­p nháº­t user_message_id_db vÃ o state.
    Node nÃ y cháº¡y ngay sau check_scope_node Ä‘á»ƒ Ä‘áº£m báº£o user_message_id_db luÃ´n cÃ³.
    """
    async def _async_persist_user_interaction():
        result_state = state.copy()
        try:
            logger.info("ğŸ’¾ Persist user interaction node - Ä‘ang lÆ°u user message...")
            
            # TÃ¬m tin nháº¯n ngÆ°á»i dÃ¹ng Ä‘Ã£ tá»“n táº¡i trong database
            from sqlalchemy import desc
            from app.db.models import Message
            
            db = repository.db
            existing_message = db.query(Message).filter(
                Message.conversation_id == result_state['conversation_id'],
                Message.role == "user",
                Message.content == result_state['user_message']
            ).order_by(desc(Message.created_at)).first()
            
            if existing_message:
                # Tin nháº¯n Ä‘Ã£ tá»“n táº¡i, chá»‰ cáº­p nháº­t ID
                result_state['user_message_id_db'] = existing_message.message_id
                logger.info(f"ğŸ“Œ User message Ä‘Ã£ tá»“n táº¡i vá»›i ID: {existing_message.message_id}")
            else:
                # LUÃ”N lÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u, báº¥t ká»ƒ pháº¡m vi
                user_message_db_obj = repository.add_message(
                    result_state['conversation_id'], 
                    "user", 
                    result_state['user_message']
                )
                result_state['user_message_id_db'] = user_message_db_obj.message_id
                logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u user message vá»›i ID: {user_message_db_obj.message_id}")
            
            # Táº¡o user_message object Ä‘á»ƒ Ä‘á»“ng nháº¥t vá»›i response format
            result_state["user_message"] = {
                "role": "user",
                "content": result_state['user_message']
            }
            
            # LÆ°u thÃ´ng tin sá»©c khá»e vÃ o database náº¿u cÃ³ collected_info vÃ  thuá»™c pháº¡m vi há»£p lá»‡
            if (result_state.get('collected_info') and 
                result_state.get('is_valid_scope') and 
                not result_state.get('is_greeting')):
                
                try:
                    await save_health_data_to_db(
                        repository, 
                        result_state['conversation_id'], 
                        result_state['user_id'], 
                        result_state['collected_info']
                    )
                    logger.info("ğŸ’¾ ÄÃ£ lÆ°u collected_info vÃ o HealthData database")
                except Exception as health_error:
                    logger.error(f"âš ï¸ Lá»—i khi lÆ°u health_data: {health_error}")
                    # KhÃ´ng fail toÃ n bá»™ process vÃ¬ lá»—i health_data
            
            logger.info(f"âœ… Persist user interaction hoÃ n táº¥t. user_message_id_db: {result_state.get('user_message_id_db')}")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ Lá»—i trong persist_user_interaction_node: {e}", exc_info=True)
            result_state['error'] = f"Lá»—i lÆ°u user message: {str(e)}"
            # KhÃ´ng fail hard, Ä‘á»ƒ luá»“ng tiáº¿p tá»¥c
        
        return result_state

    return asyncio.run(_async_persist_user_interaction())

def collect_info_node(state: ChatState) -> ChatState:
    """Thu tháº­p thÃªm thÃ´ng tin tá»« ngÆ°á»i dÃ¹ng"""
    logger.info("ğŸ“ Äang chuáº©n bá»‹ thu tháº­p thÃªm thÃ´ng tin...")
    
    # Náº¿u lÃ  tin nháº¯n chÃ o há»i thÃ¬ bá» qua bÆ°á»›c nÃ y
    if state['is_greeting']:
        return state
    
    # Náº¿u cáº§n thÃªm thÃ´ng tin, chuáº©n bá»‹ cÃ¢u há»i tiáº¿p theo
    if state['need_more_info'] and state['follow_up_question']:
        logger.info(f"â“ Cáº§n thu tháº­p thÃªm thÃ´ng tin: {state['follow_up_question']}")
        state['final_response'] = state['follow_up_question']
    else:
        # Náº¿u Ä‘Ã£ Ä‘á»§ thÃ´ng tin, chá»‰ cáº­p nháº­t tráº¡ng thÃ¡i
        state['need_more_info'] = False
    
    return state

# Wrapper cho cÃ¡c hÃ m báº¥t Ä‘á»“ng bá»™
def run_async(async_func):
    async def wrapped(*args, **kwargs):
        return await async_func(*args, **kwargs)
    
    def wrapper(*args, **kwargs):
        return asyncio.run(wrapped(*args, **kwargs))
    
    return wrapper

def store_data_node_wrapper(state: ChatState, repository) -> ChatState:
    """
    Wrapper Ä‘á»“ng bá»™ cho hÃ m store_data_node báº¥t Ä‘á»“ng bá»™.
    âš ï¸ CHÃš Ã: user_message_id_db Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ trong persist_user_interaction_node.
    Node nÃ y giá» chá»‰ xá»­ lÃ½ cÃ¡c logic cÃ²n láº¡i náº¿u cáº§n.
    """
    async def _async_store_data():
        result_state = state.copy()
        try:
            logger.info("ğŸ“‚ Store data node - xá»­ lÃ½ logic bá»• sung...")
            
            # Logic bá»• sung cÃ³ thá»ƒ thÃªm á»Ÿ Ä‘Ã¢y náº¿u cáº§n
            # user_message_id_db Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ trong persist_user_interaction_node
            
            # XÃ¡c nháº­n user_message_id_db Ä‘Ã£ cÃ³
            if not result_state.get('user_message_id_db'):
                logger.warning("âš ï¸ user_message_id_db chÆ°a cÃ³ trong store_data_node")
            else:
                logger.info(f"âœ… Store data node: user_message_id_db = {result_state['user_message_id_db']}")
                
        except Exception as e:
            logger.error(f"ğŸ’¥ Lá»—i trong store_data_node: {e}", exc_info=True)
            result_state['error'] = f"Lá»—i trong store_data: {str(e)}"
        
        return result_state

    return asyncio.run(_async_store_data())

def medichat_call_node_wrapper(state: ChatState, repository, llm_service) -> ChatState:
    """Wrapper Ä‘á»“ng bá»™ cho hÃ m medichat_call_node báº¥t Ä‘á»“ng bá»™"""
    async def _async_medichat_call():
        result_state = state.copy()
        
        # Bá» qua náº¿u khÃ´ng há»£p lá»‡ hoáº·c cáº§n thÃªm thÃ´ng tin
        if not result_state['is_valid_scope'] or result_state['need_more_info'] or result_state['error'] or result_state['is_greeting']:
            return result_state

        try:
            gemini_service = GeminiPromptService()
            
            # Láº¥y toÃ n bá»™ lá»‹ch sá»­ trÃ² chuyá»‡n
            messages = repository.get_messages_with_summary(result_state['conversation_id'])
            
            # ThÃªm tin nháº¯n hiá»‡n táº¡i náº¿u chÆ°a cÃ³
            current_user_message_exists = False
            for msg in messages:
                if msg["role"] == "user" and msg["content"] == result_state['user_message']:
                    current_user_message_exists = True
                    break
            
            if not current_user_message_exists:
                messages.append({"role": "user", "content": result_state['user_message']})
            
            # Táº¡o prompt cho Medichat
            medichat_prompt = await gemini_service.create_medichat_prompt(messages)
            result_state['medichat_prompt'] = medichat_prompt
            
            # Khá»Ÿi táº¡o LLM service náº¿u cáº§n
            if llm_service._active_service is None:
                await llm_service.initialize()
            
            # Táº¡o danh sÃ¡ch tin nháº¯n má»›i vá»›i prompt tá»« Gemini
            medichat_messages = [
                {
                    "role": "system", 
                    "content": settings.MEDICHAT_SYSTEM_PROMPT
                },
                {
                    "role": "user",
                    "content": result_state['medichat_prompt']
                }
            ]
            
            # Gá»i Ä‘áº¿n Medichat Ä‘á»ƒ láº¥y pháº£n há»“i
            logger.info(f"ğŸ“ Gá»­i prompt Ä‘áº¿n Medichat: {result_state['medichat_prompt'][:100]}...")
            medichat_response = await llm_service.get_full_response(medichat_messages)
            result_state['medichat_response'] = medichat_response
            
            logger.info(f"âœ… ÄÃ£ nháº­n pháº£n há»“i tá»« Medichat: {medichat_response[:50]}...")
        except Exception as e:
            logger.error(f"ğŸ’¥ Lá»—i khi gá»i Ä‘áº¿n Medichat: {str(e)}", exc_info=True)
            result_state['error'] = f"Lá»—i khi gá»i Ä‘áº¿n Medichat: {str(e)}"
        
        return result_state

    return asyncio.run(_async_medichat_call())

def response_cleanup_node_wrapper(state: ChatState, repository) -> ChatState:
    """Wrapper Ä‘á»“ng bá»™ cho hÃ m response_cleanup_node báº¥t Ä‘á»“ng bá»™"""
    async def _async_response_cleanup():
        result_state = state.copy()

        # Xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p
        try:
            if not result_state['is_valid_scope']:
                # Cáº­p nháº­t thÃ´ng bÃ¡o tá»« chá»‘i Ä‘á»ƒ pháº£n Ã¡nh Ä‘Ãºng pháº¡m vi tÆ° váº¥n
                result_state['final_response'] = ("Xin lá»—i, cÃ¢u há»i cá»§a báº¡n náº±m ngoÃ i pháº¡m vi tÆ° váº¥n cá»§a tÃ´i. "
                                                "TÃ´i chá»‰ cÃ³ thá»ƒ há»— trá»£ vá» cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n dinh dÆ°á»¡ng, sá»©c khá»e, "
                                                "mÃ³n Äƒn vÃ  Ä‘á»“ uá»‘ng. Báº¡n cÃ³ thá»ƒ Ä‘áº·t cÃ¢u há»i khÃ¡c trong pháº¡m vi nÃ y khÃ´ng?")
            
            elif result_state['is_greeting']:
                if not result_state['final_response']:
                    result_state['final_response'] = "Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ tÆ° váº¥n dinh dÆ°á»¡ng vÃ  sá»©c khá»e. TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n hÃ´m nay?"
            
            elif result_state['need_more_info'] and result_state['follow_up_question']:
                pass
            
            elif result_state['error']:
                result_state['final_response'] = "Xin lá»—i, hiá»‡n tÃ´i khÃ´ng thá»ƒ káº¿t ná»‘i tá»›i há»‡ thá»‘ng trÃ­ tuá»‡ nhÃ¢n táº¡o. Vui lÃ²ng thá»­ láº¡i sau."
            
            elif result_state['medichat_response']:
                # Polish response
                gemini_service = GeminiPromptService()
                if result_state['medichat_prompt']:
                    polished_response = await gemini_service.polish_response(
                        result_state['medichat_response'], 
                        result_state['medichat_prompt']
                    )
                    result_state['final_response'] = polished_response
                else:
                    result_state['final_response'] = result_state['medichat_response']
            else:
                result_state['final_response'] = "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ xá»­ lÃ½ yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i."
                
            logger.info(f"ğŸ“ Pháº£n há»“i cuá»‘i cÃ¹ng: {result_state['final_response'][:50]}...")
            
            # LUÃ”N lÆ°u pháº£n há»“i vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u vÃ  cáº­p nháº­t assistant_message_id_db
            if result_state['final_response']:
                assistant_message_db_obj = repository.add_message(result_state['conversation_id'], "assistant", result_state['final_response'])
                result_state['assistant_message_id_db'] = assistant_message_db_obj.message_id
                logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u pháº£n há»“i trá»£ lÃ½ vá»›i ID={assistant_message_db_obj.message_id}: {result_state['final_response'][:50]}...")
                
                result_state["assistant_message"] = {
                    "role": "assistant",
                    "content": result_state['final_response']
                }
        except Exception as e:
            logger.error(f"ğŸ’¥ Lá»—i khi xá»­ lÃ½ pháº£n há»“i: {str(e)}", exc_info=True)
            result_state['error'] = f"Lá»—i khi xá»­ lÃ½ pháº£n há»“i: {str(e)}"
            result_state['final_response'] = "Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ pháº£n há»“i. Vui lÃ²ng thá»­ láº¡i sau."

        return result_state

    return asyncio.run(_async_response_cleanup())

async def save_health_data_to_cache(conversation_id: int, user_id: int, data: Dict[str, Any]) -> None:
    """LÆ°u thÃ´ng tin sá»©c khá»e vÃ o Redis Cache vá»›i TTL"""
    try:
        cache_key = f"session:{conversation_id}:health_info"
        cache_data = {
            "user_id": user_id,
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
        CacheService.set_cache(cache_key, cache_data, ttl=CacheService.TTL_LONG)
        logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u thÃ´ng tin sá»©c khá»e vÃ o cache: {cache_key}")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Lá»—i khi lÆ°u thÃ´ng tin sá»©c khá»e vÃ o cache: {str(e)}")

async def save_health_data_to_db(repo, conversation_id: int, user_id: int, data: Dict[str, Any]) -> None:
    """LÆ°u thÃ´ng tin sá»©c khá»e vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u"""
    try:
        # Lá»c dá»¯ liá»‡u theo cÃ¡c trÆ°á»ng Ä‘Æ°á»£c há»— trá»£
        health_condition = data.get('health_condition')
        medical_history = data.get('medical_history')
        allergies = data.get('allergies')
        dietary_habits = data.get('dietary_habits')
        health_goals = data.get('health_goals')
        
        # LÆ°u additional_info cho cÃ¡c thÃ´ng tin khÃ¡c
        additional_info = {k: v for k, v in data.items() 
                         if k not in ['health_condition', 'medical_history', 'allergies', 'dietary_habits', 'health_goals']}
        
        health_data = repo.save_health_data(
            conversation_id=conversation_id,
            user_id=user_id,
            health_condition=health_condition,
            medical_history=medical_history,
            allergies=allergies,
            dietary_habits=dietary_habits,
            health_goals=health_goals,
            additional_info=additional_info
        )
        
        logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u thÃ´ng tin sá»©c khá»e vÃ o DB: conversation_id={conversation_id}")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Lá»—i khi lÆ°u thÃ´ng tin sá»©c khá»e vÃ o DB: {str(e)}")

async def recipe_search_node(state: ChatState) -> ChatState:
    """TÃ¬m kiáº¿m cÃ´ng thá»©c mÃ³n Äƒn tá»« database"""
    logger.info("ğŸ” Báº¯t Ä‘áº§u tÃ¬m kiáº¿m cÃ´ng thá»©c mÃ³n Äƒn...")
    
    try:
        gemini_service = GeminiPromptService()
        
        # Táº¡o query tÃ¬m kiáº¿m vá»›i suggest_general_if_needed
        suggest_general_if_needed = state.get('suggest_general_options', False)
        
        search_query = await gemini_service.create_recipe_search_prompt(
            state['user_message'], 
            state.get('collected_info', {}),
            suggest_general_if_needed=suggest_general_if_needed
        )
        
        logger.info(f"ğŸ” Recipe search query: {search_query}")
        
        # Gá»i recipe tool (synchronous function - khÃ´ng await)
        recipe_json_str = search_and_filter_recipes(search_query)
        
        # Parse JSON result vá»›i error handling máº¡nh máº½
        recipes = []
        if recipe_json_str:
            try:
                recipes_data = json.loads(recipe_json_str)
                
                # Kiá»ƒm tra Ä‘á»‹nh dáº¡ng tráº£ vá» tá»« recipe_tool
                if isinstance(recipes_data, list) and all(isinstance(item, dict) for item in recipes_data):
                    recipes = recipes_data
                elif isinstance(recipes_data, dict) and "recipes" in recipes_data and isinstance(recipes_data["recipes"], list):
                    # TrÆ°á»ng há»£p recipe_tool tráº£ vá» {"recipes": [...], "errors": [...]}
                    recipes = recipes_data["recipes"]
                    if "errors" in recipes_data and recipes_data["errors"]:
                        logger.warning(f"âš ï¸ Lá»—i tá»« recipe_tool: {recipes_data['errors']}")
                elif isinstance(recipes_data, dict) and "error" in recipes_data:
                    logger.error(f"ğŸ’¥ Recipe tool tráº£ vá» lá»—i: {recipes_data['error']}")
                    recipes = []
                else:
                    logger.warning(f"âš ï¸ Recipe tool tráº£ vá» Ä‘á»‹nh dáº¡ng khÃ´ng mong muá»‘n: {type(recipes_data)}")
                    recipes = []
                    
            except json.JSONDecodeError as json_error:
                logger.error(f"ğŸ’¥ Lá»—i parse JSON tá»« recipe_tool: {str(json_error)}")
                logger.error(f"Raw response (first 200 chars): {recipe_json_str[:200]}")
                recipes = []
                # KhÃ´ng set error vÃ¬ recipe search khÃ´ng pháº£i critical
        else:
            logger.warning("âš ï¸ Recipe tool khÃ´ng tráº£ vá» káº¿t quáº£.")
            recipes = []

        if recipes:
            # Lá»c trÃ¹ng láº·p báº±ng Gemini (hÃ m nÃ y lÃ  async)
            try:
                filtered_recipes = await gemini_service.filter_duplicate_recipes(recipes)
                state['recipe_results'] = filtered_recipes[:10]  # Giá»›i háº¡n 10 recipes tá»‘t nháº¥t
                logger.info(f"âœ… ÄÃ£ lá»c tá»« {len(recipes)} xuá»‘ng {len(filtered_recipes)} recipes, lÆ°u {len(state['recipe_results'])} recipes")
            except Exception as filter_error:
                logger.error(f"ğŸ’¥ Lá»—i khi lá»c recipes: {str(filter_error)}")
                # Fallback: sá»­ dá»¥ng recipes chÆ°a lá»c, giá»›i háº¡n 10
                state['recipe_results'] = recipes[:10]
                logger.info(f"âœ… Sá»­ dá»¥ng {len(state['recipe_results'])} recipes chÆ°a lá»c (fallback)")
        else:
            state['recipe_results'] = []
            logger.info("âŒ KhÃ´ng tÃ¬m tháº¥y cÃ´ng thá»©c mÃ³n Äƒn phÃ¹ há»£p sau khi parse.")
            
    except Exception as e:
        logger.error(f"ğŸ’¥ Lá»—i nghiÃªm trá»ng khi tÃ¬m kiáº¿m cÃ´ng thá»©c: {str(e)}", exc_info=True)
        state['recipe_results'] = []
        # KhÃ´ng set error Ä‘á»ƒ khÃ´ng cháº·n luá»“ng xá»­ lÃ½ tiáº¿p theo
        logger.info("ğŸ”„ Tiáº¿p tá»¥c xá»­ lÃ½ mÃ  khÃ´ng cÃ³ recipes")
    
    return state

async def product_search_node(state: ChatState) -> ChatState:
    """TÃ¬m kiáº¿m sáº£n pháº©m tá»« medichat response vÃ  recipe results"""
    logger.info("ğŸ›’ Báº¯t Ä‘áº§u tÃ¬m kiáº¿m sáº£n pháº©m...")
    
    try:
        # Chá»‰ tÃ¬m kiáº¿m sáº£n pháº©m náº¿u cÃ³ medichat_response
        if not state.get('medichat_response'):
            logger.info("âŒ KhÃ´ng cÃ³ medichat_response Ä‘á»ƒ tÃ¬m kiáº¿m sáº£n pháº©m")
            state['product_results'] = {}
            return state
        
        gemini_service = GeminiPromptService()
        
        # Táº¡o product search prompt vá»›i cáº£ recipes vÃ  beverages
        product_search_prompt = await gemini_service.create_product_search_prompt(
            state['medichat_response'],
            state.get('recipe_results'),
            state.get('beverage_results')
        )
        
        logger.info(f"ğŸ›’ Product search prompt: {product_search_prompt}")
        
        # Gá»i product tool (async function)
        product_results = await process_user_request_async(product_search_prompt)
        
        if product_results:
            state['product_results'] = product_results
            logger.info(f"âœ… TÃ¬m tháº¥y thÃ´ng tin sáº£n pháº©m")
        else:
            state['product_results'] = {}
            logger.info("âŒ KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p")
            
    except Exception as e:
        logger.error(f"ğŸ’¥ Lá»—i khi tÃ¬m kiáº¿m sáº£n pháº©m: {str(e)}", exc_info=True)
        state['product_results'] = {}
        # KhÃ´ng set error á»Ÿ Ä‘Ã¢y vÃ¬ product search lÃ  optional
    
    return state

async def beverage_search_node(state: ChatState) -> ChatState:
    """
    â­ NODE Má»šI: TÃ¬m kiáº¿m Ä‘á»“ uá»‘ng tá»« product_beverage tool vá»›i async optimization.
    Sá»­ dá»¥ng fetch_and_filter_drinks_in_batches_async Ä‘á»ƒ láº¥y danh sÃ¡ch Ä‘á»“ uá»‘ng.
    """
    logger.info("ğŸ¥¤ Báº¯t Ä‘áº§u tÃ¬m kiáº¿m Ä‘á»“ uá»‘ng...")
    
    try:
        # â­ KHá»I Táº O SERVICES (Cáº¬P NHáº¬T CHO VERSION Má»šI)
        loop = asyncio.get_event_loop()
        pinecone_index, vector_dimension = await loop.run_in_executor(
            None, init_services
        )
        
        logger.info(f"ğŸ”§ ÄÃ£ khá»Ÿi táº¡o services: vector_dim={vector_dimension}")
        
        # â­ Gá»ŒI HÃ€M ASYNC Má»šI TRá»°C TIáº¾P
        beverages_data = await fetch_and_filter_drinks_in_batches_async(pinecone_index, vector_dimension)
        
        if beverages_data and isinstance(beverages_data, list):
            state['beverage_results'] = beverages_data
            logger.info(f"âœ… TÃ¬m tháº¥y {len(beverages_data)} Ä‘á»“ uá»‘ng.")
            # Log má»™t vÃ i sáº£n pháº©m Ä‘áº§u Ä‘á»ƒ debug
            for i, beverage in enumerate(beverages_data[:3]):
                logger.info(f"   - Äá»“ uá»‘ng {i+1}: {beverage.get('product_name', 'N/A')}")
        else:
            state['beverage_results'] = []
            logger.info("âŒ KhÃ´ng tÃ¬m tháº¥y Ä‘á»“ uá»‘ng phÃ¹ há»£p.")
            
    except Exception as e:
        logger.error(f"ğŸ’¥ Lá»—i khi tÃ¬m kiáº¿m Ä‘á»“ uá»‘ng: {str(e)}", exc_info=True)
        state['beverage_results'] = []
        # KhÃ´ng set state['error'] Ä‘á»ƒ luá»“ng cÃ³ thá»ƒ tiáº¿p tá»¥c
        logger.info("ğŸ”„ Tiáº¿p tá»¥c xá»­ lÃ½ mÃ  khÃ´ng cÃ³ beverage results")
    
    return state

def enhanced_medichat_call_node_wrapper(state: ChatState, repository, llm_service) -> ChatState:
    """
    Enhanced medichat call vá»›i recipes náº¿u cÃ³.
    Truyá»n Ä‘Ãºng cá» suggest_general_options khi táº¡o prompt.
    """
    async def _async_enhanced_medichat_call():
        result_state = state.copy()
        
        # Bá» qua náº¿u khÃ´ng há»£p lá»‡ hoáº·c cáº§n thÃªm thÃ´ng tin
        if not result_state['is_valid_scope'] or result_state['need_more_info'] or result_state['error'] or result_state['is_greeting']:
            return result_state

        try:
            gemini_service = GeminiPromptService()
            
            # Láº¥y toÃ n bá»™ lá»‹ch sá»­ trÃ² chuyá»‡n
            messages = repository.get_messages_with_summary(result_state['conversation_id'])
            
            # ThÃªm tin nháº¯n hiá»‡n táº¡i náº¿u chÆ°a cÃ³
            current_user_message_exists = False
            for msg in messages:
                if msg["role"] == "user" and msg["content"] == result_state['user_message']:
                    current_user_message_exists = True
                    break
            
            if not current_user_message_exists:
                messages.append({"role": "user", "content": result_state['user_message']})
            
            # Láº¥y cá» suggest_general tá»« state
            suggest_general = result_state.get('suggest_general_options', False)
            
            # Láº¥y recipes vÃ  beverages tá»« state vá»›i kiá»ƒm tra an toÃ n
            recipe_list = result_state.get('recipe_results')
            if recipe_list is None:
                recipe_list = []
            
            beverage_list = result_state.get('beverage_results')
            if beverage_list is None:
                beverage_list = []
            
            # Náº¿u cÃ³ recipe results hoáº·c beverage results, táº¡o enhanced prompt
            if result_state.get('is_food_related') and (recipe_list or beverage_list):
                # Táº¡o prompt vá»›i recipes, beverages vÃ  suggest_general sá»­ dá»¥ng method enhanced
                medichat_prompt = await gemini_service.create_enhanced_medichat_prompt(messages, recipe_list, beverage_list, suggest_general)
                result_state['medichat_prompt'] = medichat_prompt
                logger.info(f"ğŸ“ Táº¡o enhanced prompt vá»›i {len(recipe_list)} recipes, {len(beverage_list)} beverages, suggest_general={suggest_general}")
                
            elif suggest_general:
                # TrÆ°á»ng há»£p suggest_general=true nhÆ°ng khÃ´ng cÃ³ recipes/beverages
                medichat_prompt = await gemini_service.create_enhanced_medichat_prompt(messages, None, None, suggest_general)
                result_state['medichat_prompt'] = medichat_prompt
                logger.info(f"ğŸ“ Táº¡o enhanced prompt vá»›i suggest_general=True, khÃ´ng cÃ³ recipes/beverages")
                
            else:
                # Táº¡o prompt thÃ´ng thÆ°á»ng
                medichat_prompt = await gemini_service.create_medichat_prompt(messages)
                result_state['medichat_prompt'] = medichat_prompt
                logger.info(f"ğŸ“ Táº¡o prompt thÃ´ng thÆ°á»ng")
            
            # Khá»Ÿi táº¡o LLM service náº¿u cáº§n
            if llm_service._active_service is None:
                await llm_service.initialize()
            
            # Táº¡o danh sÃ¡ch tin nháº¯n má»›i vá»›i prompt tá»« Gemini
            medichat_messages = [
                {
                    "role": "system", 
                    "content": settings.MEDICHAT_SYSTEM_PROMPT
                },
                {
                    "role": "user",
                    "content": result_state['medichat_prompt']
                }
            ]
            
            # Gá»i Ä‘áº¿n Medichat Ä‘á»ƒ láº¥y pháº£n há»“i
            logger.info(f"ğŸ“ Gá»­i enhanced prompt Ä‘áº¿n Medichat: {result_state['medichat_prompt'][:100]}...")
            medichat_response = await llm_service.get_full_response(medichat_messages)
            result_state['medichat_response'] = medichat_response
            
            logger.info(f"âœ… ÄÃ£ nháº­n pháº£n há»“i tá»« Enhanced Medichat: {medichat_response[:50]}...")
        except Exception as e:
            logger.error(f"ğŸ’¥ Lá»—i khi gá»i Ä‘áº¿n Enhanced Medichat: {str(e)}", exc_info=True)
            result_state['error'] = f"Lá»—i khi gá»i Ä‘áº¿n Medichat: {str(e)}"
        
        return result_state

    return asyncio.run(_async_enhanced_medichat_call())

def enhanced_response_cleanup_node_wrapper(state: ChatState, repository) -> ChatState:
    """
    Enhanced response cleanup vá»›i thÃ´ng tin recipes vÃ  products.
    CÃ³ fallback táº¡o gá»£i Ã½ chung náº¿u suggest_general_options=true nhÆ°ng Medichat khÃ´ng pháº£n há»“i.
    LÆ°u assistant_message_id_db vÃ o state.
    """
    async def _async_enhanced_response_cleanup():
        result_state = state.copy()

        # Xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p
        try:
            if not result_state['is_valid_scope']:
                # Cáº­p nháº­t thÃ´ng bÃ¡o tá»« chá»‘i Ä‘á»ƒ pháº£n Ã¡nh Ä‘Ãºng pháº¡m vi tÆ° váº¥n
                result_state['final_response'] = ("Xin lá»—i, cÃ¢u há»i cá»§a báº¡n náº±m ngoÃ i pháº¡m vi tÆ° váº¥n cá»§a tÃ´i. "
                                                "TÃ´i chá»‰ cÃ³ thá»ƒ há»— trá»£ vá» cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n dinh dÆ°á»¡ng, sá»©c khá»e, "
                                                "mÃ³n Äƒn vÃ  Ä‘á»“ uá»‘ng. Báº¡n cÃ³ thá»ƒ Ä‘áº·t cÃ¢u há»i khÃ¡c trong pháº¡m vi nÃ y khÃ´ng?")
            
            elif result_state['is_greeting']:
                if not result_state['final_response']:
                    result_state['final_response'] = "Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ tÆ° váº¥n dinh dÆ°á»¡ng vÃ  sá»©c khá»e. TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n hÃ´m nay?"
            
            elif result_state['need_more_info'] and result_state['follow_up_question']:
                pass
            
            elif result_state['error']:
                result_state['final_response'] = "Xin lá»—i, hiá»‡n tÃ´i khÃ´ng thá»ƒ káº¿t ná»‘i tá»›i há»‡ thá»‘ng trÃ­ tuá»‡ nhÃ¢n táº¡o. Vui lÃ²ng thá»­ láº¡i sau."
            
            elif result_state['medichat_response']:
                # XÃ¢y dá»±ng comprehensive response cho food/beverage-related queries
                if result_state.get('is_food_related') and (result_state.get('recipe_results') or result_state.get('beverage_results') or result_state.get('product_results')):
                    comprehensive_parts = [result_state['medichat_response']]
                    
                    # â­ THÃŠM THÃ”NG TIN BEVERAGE RESULTS Náº¾U CÃ“
                    beverages = result_state.get('beverage_results')
                    if beverages is None:
                        beverages = []
                    if beverages:
                        beverage_section = "\n\nğŸ¥¤ **Äá»’ Uá»NG Gá»¢I Ã Tá»ª DATABASE**"
                        for i, beverage in enumerate(beverages[:8]):  # Giá»›i háº¡n 8 Ä‘á»“ uá»‘ng
                            product_name = beverage.get('product_name', 'N/A')
                            product_id = beverage.get('product_id', 'N/A')
                            beverage_section += f"\n{i+1}. {product_name} (ID: {product_id})"
                        
                        if len(beverages) > 8:
                            beverage_section += f"\n... vÃ  {len(beverages) - 8} Ä‘á»“ uá»‘ng khÃ¡c"
                        
                        comprehensive_parts.append(beverage_section)
                    
                    # ThÃªm thÃ´ng tin recipes náº¿u cÃ³  
                    recipes = result_state.get('recipe_results')
                    if recipes is None:
                        recipes = []
                    if recipes:
                        recipe_section = "\n\nğŸ“ **CÃ”NG THá»¨C Gá»¢I Ã Tá»ª DATABASE**"
                        for i, recipe in enumerate(recipes[:5], 1):
                            name = recipe.get('name', 'N/A')
                            url = recipe.get('url', '')
                            ingredients = recipe.get('ingredients_summary', 'N/A')
                            recipe_section += f"\n{i}. **{name}**"
                            if ingredients and ingredients != 'N/A':
                                recipe_section += f"\n   - NguyÃªn liá»‡u: {ingredients}"
                            if url:
                                recipe_section += f"\n   - Link: {url}"
                        comprehensive_parts.append(recipe_section)
                    
                    # ThÃªm thÃ´ng tin products náº¿u cÃ³
                    products = result_state.get('product_results', {})
                    if products and products.get('ingredient_mapping_results'):
                        available_products = []
                        unavailable_ingredients = []
                        
                        for mapping in products['ingredient_mapping_results']:
                            ingredient = mapping.get('requested_ingredient', '')
                            product_id = mapping.get('product_id')
                            product_name = mapping.get('product_name')
                            
                            if product_id and product_name:
                                available_products.append(f"â€¢ {ingredient} â†’ {product_name}")
                            elif ingredient:
                                unavailable_ingredients.append(f"â€¢ {ingredient}")
                        
                        if available_products:
                            products_section = "\n\nğŸ›’ **Sáº¢N PHáº¨M CÃ“ Sáº´N TRONG Cá»¬A HÃ€NG**\n" + "\n".join(available_products[:10])
                            comprehensive_parts.append(products_section)
                        
                        if unavailable_ingredients:
                            unavailable_section = "\n\nâš ï¸ **NGUYÃŠN LIá»†U Cáº¦N TÃŒM NGUá»’N KHÃC**\n" + "\n".join(unavailable_ingredients[:5])
                            comprehensive_parts.append(unavailable_section)
                    
                    # GhÃ©p thÃ nh response hoÃ n chá»‰nh
                    raw_comprehensive_response = "\n".join(comprehensive_parts)
                    
                    # Polish response
                    gemini_service = GeminiPromptService()
                    if result_state['medichat_prompt']:
                        polished_response = await gemini_service.polish_response(
                            raw_comprehensive_response, 
                            result_state['medichat_prompt']
                        )
                        result_state['final_response'] = polished_response
                    else:
                        result_state['final_response'] = raw_comprehensive_response
                        
                else:
                    # Polish response thÃ´ng thÆ°á»ng
                    gemini_service = GeminiPromptService()
                    if result_state['medichat_prompt']:
                        polished_response = await gemini_service.polish_response(
                            result_state['medichat_response'], 
                            result_state['medichat_prompt']
                        )
                        result_state['final_response'] = polished_response
                    else:
                        result_state['final_response'] = result_state['medichat_response']
                        # â­ KIá»‚M TRA: Náº¿u chÆ°a cÃ³ final_response, táº¡o fallback
            if not result_state.get('final_response'):
                if result_state.get('suggest_general_options', False) and result_state.get('is_valid_scope', True):
                    logger.info("ğŸ¯ Enhanced Fallback: Táº¡o gá»£i Ã½ chung phong phÃº vÃ¬ suggest_general_options=True")
                    
                    # â­ Sá»¬ Dá»¤NG TEMPLATE Cá» Äá»ŠNH CHáº¤T LÆ¯á»¢NG CAO 
                    logger.info("ğŸ“ Táº¡o gá»£i Ã½ chung tá»« template cÃ³ sáºµn")
                    
                    # Template cá»‘ Ä‘á»‹nh cháº¥t lÆ°á»£ng cao
                    import random
                    suggestion_templates = [
                        ("Dáº¡, tÃ´i hiá»ƒu báº¡n muá»‘n cÃ³ má»™t sá»‘ gá»£i Ã½ chung vá» mÃ³n Äƒn tá»‘t cho sá»©c khá»e. "
                        "Dá»±a trÃªn cÃ¡c tiÃªu chÃ­ phá»• biáº¿n, cÃ¢n báº±ng dinh dÆ°á»¡ng vÃ  dá»… cháº¿ biáº¿n, "
                        "tÃ´i xin Ä‘á» xuáº¥t má»™t sá»‘ lá»±a chá»n:\n\n"
                        "ğŸ¥— **Salad rau cá»§ quáº£** - Nhiá»u cháº¥t xÆ¡, vitamin, khoÃ¡ng cháº¥t tá»± nhiÃªn\n"
                        "ğŸ² **Canh chua cÃ¡** - GiÃ u protein, vitamin C, dá»… tiÃªu hÃ³a\n"
                        "ğŸ¥£ **ChÃ¡o gÃ ** - Dá»… Äƒn, bá»• dÆ°á»¡ng, phÃ¹ há»£p nhiá»u lá»©a tuá»•i\n"
                        "ğŸ¥¤ **NÆ°á»›c Ã©p trÃ¡i cÃ¢y tÆ°Æ¡i** - Vitamin tá»± nhiÃªn, tÄƒng cÆ°á»ng miá»…n dá»‹ch\n\n"
                        "Nhá»¯ng mÃ³n nÃ y thÆ°á»ng dá»… tÃ¬m nguyÃªn liá»‡u, tá»‘t cho sá»©c khá»e vÃ  Ã­t gÃ¢y dá»‹ á»©ng. "
                        "Báº¡n cÃ³ muá»‘n tÃ´i tÆ° váº¥n cá»¥ thá»ƒ hÆ¡n vá» mÃ³n nÃ o khÃ´ng?"),
                        
                        ("Dáº¡, Ä‘á»ƒ gá»£i Ã½ cÃ¡c mÃ³n Äƒn phÃ¹ há»£p chung, tÃ´i cÃ³ thá»ƒ Ä‘á» xuáº¥t má»™t sá»‘ lá»±a chá»n "
                        "dá»±a trÃªn tÃ­nh cÃ¢n báº±ng dinh dÆ°á»¡ng vÃ  Ä‘á»™ phá»• biáº¿n:\n\n"
                        "ğŸœ **Phá»Ÿ gÃ ** - Nháº¹, dá»… Äƒn, Ä‘áº§y Ä‘á»§ cháº¥t dinh dÆ°á»¡ng\n"
                        "ğŸ¥™ **BÃ¡nh mÃ¬ káº¹p rau** - Tiá»‡n lá»£i, cÃ³ thá»ƒ tÃ¹y chá»‰nh nguyÃªn liá»‡u\n"
                        "ğŸ¯ **Sá»¯a chua máº­t ong** - Probiotics tá»‘t cho tiÃªu hÃ³a\n"
                        "ğŸ¥ **BÃ¡nh yáº¿n máº¡ch chuá»‘i** - Cháº¥t xÆ¡ cao, nÄƒng lÆ°á»£ng bá»n vá»¯ng\n\n"
                        "ÄÃ¢y lÃ  nhá»¯ng lá»±a chá»n an toÃ n vÃ  Ä‘Æ°á»£c nhiá»u ngÆ°á»i yÃªu thÃ­ch. "
                        "Báº¡n cÃ³ thá»ƒ chia sáº» thÃªm vá» sá»Ÿ thÃ­ch hoáº·c nhu cáº§u cá»¥ thá»ƒ Ä‘á»ƒ tÃ´i tÆ° váº¥n chÃ­nh xÃ¡c hÆ¡n khÃ´ng?")
                    ]
                    
                    selected_template = random.choice(suggestion_templates)
                    result_state['final_response'] = selected_template
                else:
                    # Fallback cuá»‘i cÃ¹ng náº¿u khÃ´ng cÃ³ gÃ¬ khÃ¡c
                    result_state['final_response'] = ("Xin lá»—i, hiá»‡n tÃ´i khÃ´ng thá»ƒ xá»­ lÃ½ yÃªu cáº§u cá»§a báº¡n vÃ o lÃºc nÃ y. "
                                                    "Vui lÃ²ng thá»­ láº¡i sau hoáº·c Ä‘áº·t cÃ¢u há»i cá»¥ thá»ƒ hÆ¡n vá» dinh dÆ°á»¡ng, "
                                                    "mÃ³n Äƒn hoáº·c sá»©c khá»e Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ há»— trá»£ báº¡n tá»‘t hÆ¡n.")
                
            logger.info(f"ğŸ“ Pháº£n há»“i cuá»‘i cÃ¹ng: {result_state['final_response'][:50]}...")
            
            # LUÃ”N lÆ°u pháº£n há»“i vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u vÃ  cáº­p nháº­t assistant_message_id_db
            if result_state['final_response']:
                assistant_message_db_obj = repository.add_message(result_state['conversation_id'], "assistant", result_state['final_response'])
                result_state['assistant_message_id_db'] = assistant_message_db_obj.message_id
                logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u pháº£n há»“i trá»£ lÃ½ vá»›i ID={assistant_message_db_obj.message_id}: {result_state['final_response'][:50]}...")
                
                result_state["assistant_message"] = {
                    "role": "assistant",
                    "content": result_state['final_response']
                }
                
                # LÆ°u cÃ´ng thá»©c mÃ³n Äƒn vÃ o database náº¿u cÃ³ food-related results
                if (result_state.get('is_food_related') and 
                    result_state.get('recipe_results') and 
                    result_state.get('product_results')):
                    
                    try:
                        saved_menu_ids = repository.save_multiple_recipes_to_menu(
                            result_state['recipe_results'],
                            result_state['product_results']
                        )
                        
                        if saved_menu_ids:
                            logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u {len(saved_menu_ids)} cÃ´ng thá»©c mÃ³n Äƒn vÃ o database: {saved_menu_ids}")
                    except Exception as recipe_save_error:
                        logger.error(f"ğŸ’¥ Lá»—i khi lÆ°u recipes: {recipe_save_error}")
        except Exception as e:
            logger.error(f"ğŸ’¥ Lá»—i khi xá»­ lÃ½ pháº£n há»“i: {str(e)}", exc_info=True)
            result_state['error'] = f"Lá»—i khi xá»­ lÃ½ pháº£n há»“i: {str(e)}"
            result_state['final_response'] = "Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ pháº£n há»“i. Vui lÃ²ng thá»­ láº¡i sau."

        return result_state

    return asyncio.run(_async_enhanced_response_cleanup())

def define_router(state: ChatState) -> str:
    """
    â­ ROUTER Cáº¬P NHáº¬T: Sá»­ dá»¥ng requests_food vÃ  requests_beverage Ä‘á»ƒ Ä‘á»‹nh tuyáº¿n chÃ­nh xÃ¡c.
    CÃ³ logging chi tiáº¿t cho cÃ¡c cá» quan trá»ng.
    """
    # Logging cÃ¡c giÃ¡ trá»‹ cá» quan trá»ng ngay Ä‘áº§u hÃ m
    logger.info("ğŸ§­ MAIN ROUTER DECISION:")
    logger.info(f"   - is_greeting: {state.get('is_greeting', False)}")
    logger.info(f"   - is_valid_scope: {state.get('is_valid_scope', True)}")
    logger.info(f"   - user_rejected_info: {state.get('user_rejected_info', False)}")
    logger.info(f"   - need_more_info: {state.get('need_more_info', False)}")
    logger.info(f"   - suggest_general_options: {state.get('suggest_general_options', False)}")
    logger.info(f"   - is_food_related: {state.get('is_food_related', False)}")
    logger.info(f"   - requests_food: {state.get('requests_food', False)}")
    logger.info(f"   - requests_beverage: {state.get('requests_beverage', False)}")
    logger.info(f"   - error: {state.get('error', None)}")
    logger.info(f"   - user_message_id_db: {state.get('user_message_id_db', None)}")
    
    # Xá»­ lÃ½ trÆ°á»ng há»£p Ä‘áº·c biá»‡t: tin nháº¯n chÃ o há»i
    if state.get("is_greeting", False):
        logger.info("ğŸ¯ Router decision: enhanced_response_cleanup (greeting)")
        return "enhanced_response_cleanup"
    
    # Kiá»ƒm tra error
    if state.get("error"):
        logger.info("ğŸ¯ Router decision: enhanced_response_cleanup (error)")
        return "enhanced_response_cleanup"
    
    # Kiá»ƒm tra is_valid_scope
    if not state.get("is_valid_scope"):
        logger.info("ğŸ¯ Router decision: enhanced_response_cleanup (invalid scope)")
        return "enhanced_response_cleanup"
    
    # Æ¯u tiÃªn kiá»ƒm tra need_more_info trÆ°á»›c
    if state.get("need_more_info") and state.get("follow_up_question"):
        logger.info("ğŸ¯ Router decision: collect_info (need more info)")
        return "collect_info"
    
    # â­ LOGIC Má»šI: PhÃ¢n nhÃ¡nh dá»±a trÃªn requests_food vÃ  requests_beverage
    if state.get("need_more_info") == False:  # ÄÃ£ Ä‘á»§ thÃ´ng tin hoáº·c gá»£i Ã½ chung
        requests_food = state.get("requests_food", False)
        requests_beverage = state.get("requests_beverage", False)
        
        if requests_food and not requests_beverage:
            # Chá»‰ yÃªu cáº§u mÃ³n Äƒn
            logger.info("ğŸ¯ Router decision: recipe_search (food only)")
            return "recipe_search"
        elif requests_beverage and not requests_food:
            # Chá»‰ yÃªu cáº§u Ä‘á»“ uá»‘ng
            logger.info("ğŸ¯ Router decision: beverage_search (beverage only)")
            return "beverage_search"
        elif requests_food and requests_beverage:
            # YÃªu cáº§u cáº£ hai - Æ°u tiÃªn recipe_search trÆ°á»›c, sáº½ xá»­ lÃ½ beverage trong enhanced_medichat_call
            logger.info("ğŸ¯ Router decision: recipe_search (mixed - prioritize food first)")
            return "recipe_search"
        elif state.get("suggest_general_options", False) and state.get("is_food_related", False):
            # Gá»£i Ã½ chung vá» dinh dÆ°á»¡ng - Ä‘i qua recipe_search vá»›i query chung
            logger.info("ğŸ¯ Router decision: recipe_search (general food suggestions)")
            return "recipe_search"
        elif state.get("is_food_related", False):
            # Fallback cho food-related queries
            logger.info("ğŸ¯ Router decision: recipe_search (food-related fallback)")
            return "recipe_search"
        else:
            # KhÃ´ng liÃªn quan Ä‘áº¿n mÃ³n Äƒn/Ä‘á»“ uá»‘ng
            logger.info("ğŸ¯ Router decision: store_data (non-food/beverage)")
            return "store_data"
    
    # Fallback cho need_more_info != False
    if state.get("is_food_related", False):
        logger.info("ğŸ¯ Router decision: recipe_search (fallback food-related)")
        return "recipe_search"
    else:
        logger.info("ğŸ¯ Router decision: store_data (fallback non-food)")
        return "store_data"

# Router sau khi collect_info
def define_post_collect_info_router(state: ChatState) -> str:
    """
    Router sau collect_info Ä‘á»ƒ quyáº¿t Ä‘á»‹nh tiáº¿p tá»¥c hay dá»«ng.
    Sá»­ dá»¥ng requests_food vÃ  requests_beverage.
    """
    # Logging cÃ¡c giÃ¡ trá»‹ cá» quan trá»ng ngay Ä‘áº§u hÃ m
    logger.info("ğŸ§­ POST-COLLECT-INFO ROUTER DECISION:")
    logger.info(f"   - need_more_info: {state.get('need_more_info', False)}")
    logger.info(f"   - is_food_related: {state.get('is_food_related', False)}")
    logger.info(f"   - requests_food: {state.get('requests_food', False)}")
    logger.info(f"   - requests_beverage: {state.get('requests_beverage', False)}")
    logger.info(f"   - error: {state.get('error', None)}")
    
    # Náº¿u váº«n cáº§n thÃªm thÃ´ng tin hoáº·c cÃ³ lá»—i
    if state.get("need_more_info", False) or state.get("error"):
        logger.info("ğŸ¯ Post-collect router decision: enhanced_response_cleanup (still need info or error)")
        return "enhanced_response_cleanup"
    
    # â­ Sá»¬ Dá»¤NG LOGIC TÆ¯Æ NG Tá»° MAIN ROUTER
    requests_food = state.get("requests_food", False)
    requests_beverage = state.get("requests_beverage", False)
    
    if requests_food and not requests_beverage:
        logger.info("ğŸ¯ Post-collect router decision: recipe_search (food only)")
        return "recipe_search"
    elif requests_beverage and not requests_food:
        logger.info("ğŸ¯ Post-collect router decision: beverage_search (beverage only)")
        return "beverage_search"
    elif requests_food and requests_beverage:
        logger.info("ğŸ¯ Post-collect router decision: recipe_search (mixed - prioritize food first)")
        return "recipe_search"
    elif state.get("is_food_related", False):
        logger.info("ğŸ¯ Post-collect router decision: recipe_search (food-related fallback)")
        return "recipe_search"
    else:
        logger.info("ğŸ¯ Post-collect router decision: store_data (non-food)")
        return "store_data"

# Khá»Ÿi táº¡o StateGraph cho luá»“ng xá»­ lÃ½ chat
def create_chat_flow_graph(repository=None, llm_service=None):
    """â­ Cáº¬P NHáº¬T: Táº¡o vÃ  cáº¥u hÃ¬nh StateGraph vá»›i persist_user_interaction_node má»›i"""
    # Táº¡o Ä‘á»“ thá»‹ vá»›i tráº¡ng thÃ¡i lÃ  ChatState
    builder = StateGraph(ChatState)
    
    # ThÃªm cÃ¡c node cÆ¡ báº£n
    builder.add_node("check_scope", run_async(check_scope_node))
    builder.add_node("persist_user_interaction", lambda state: persist_user_interaction_node_wrapper(state, repository))
    builder.add_node("collect_info", collect_info_node)
    builder.add_node("store_data", lambda state: store_data_node_wrapper(state, repository))
    builder.add_node("medichat_call", lambda state: medichat_call_node_wrapper(state, repository, llm_service))
    builder.add_node("response_cleanup", lambda state: response_cleanup_node_wrapper(state, repository))
    
    # ThÃªm cÃ¡c node cho food flow 
    builder.add_node("recipe_search", run_async(recipe_search_node))
    builder.add_node("product_search", run_async(product_search_node))
    # â­ NODE Má»šI: Beverage search
    builder.add_node("beverage_search", run_async(beverage_search_node))
    builder.add_node("enhanced_medichat_call", lambda state: enhanced_medichat_call_node_wrapper(state, repository, llm_service))
    builder.add_node("enhanced_response_cleanup", lambda state: enhanced_response_cleanup_node_wrapper(state, repository))
    
    # â­ LUá»’NG Má»šI: check_scope â†’ persist_user_interaction â†’ router
    builder.set_entry_point("check_scope")
    builder.add_edge("check_scope", "persist_user_interaction")
    
    # Router cháº¡y sau persist_user_interaction Ä‘á»ƒ Ä‘áº£m báº£o user_message_id_db luÃ´n cÃ³
    builder.add_conditional_edges(
        "persist_user_interaction",
        define_router,
        {
            "collect_info": "collect_info",
            "enhanced_response_cleanup": "enhanced_response_cleanup",
            "store_data": "store_data",
            "recipe_search": "recipe_search",
            "beverage_search": "beverage_search"  # â­ THÃŠM EDGE CHO BEVERAGE SEARCH
        }
    )
    
    # Cáº¥u hÃ¬nh cáº¡nh tá»« collect_info
    builder.add_conditional_edges(
        "collect_info",
        define_post_collect_info_router,
        {
            "enhanced_response_cleanup": "enhanced_response_cleanup",
            "recipe_search": "recipe_search",
            "beverage_search": "beverage_search",  # â­ THÃŠM EDGE CHO BEVERAGE SEARCH
            "store_data": "store_data"
        }
    )
    
    # Food/Beverage flow sequences
    builder.add_edge("recipe_search", "enhanced_medichat_call")
    builder.add_edge("beverage_search", "enhanced_medichat_call")  # â­ BEVERAGE â†’ MEDICHAT
    builder.add_edge("enhanced_medichat_call", "product_search")
    builder.add_edge("product_search", "enhanced_response_cleanup")
    
    # Cáº¥u hÃ¬nh cáº¡nh tá»« store_data Ä‘áº¿n cÃ¡c node tiáº¿p theo
    def store_data_router(state: ChatState) -> str:
        """Router sau store_data Ä‘á»ƒ quyáº¿t Ä‘á»‹nh luá»“ng tiáº¿p theo"""
        logger.info("ğŸ§­ STORE_DATA ROUTER DECISION:")
        logger.info(f"   - is_greeting: {state.get('is_greeting', False)}")
        logger.info(f"   - is_food_related: {state.get('is_food_related', False)}")
        
        if state.get("is_greeting", False):
            logger.info("ğŸ¯ Store_data router: enhanced_response_cleanup (greeting)")
            return "enhanced_response_cleanup"
        elif state.get("is_food_related", False):
            logger.info("ğŸ¯ Store_data router: recipe_search (food-related)")
            return "recipe_search"
        else:
            logger.info("ğŸ¯ Store_data router: medichat_call (non-food)")
            return "medichat_call"
    
    builder.add_conditional_edges(
        "store_data",
        store_data_router,
        {
            "medichat_call": "medichat_call",
            "enhanced_response_cleanup": "enhanced_response_cleanup",
            "recipe_search": "recipe_search"
        }
    )
    
    # Cáº¥u hÃ¬nh cáº¡nh tá»« medichat_call Ä‘áº¿n response_cleanup
    builder.add_edge("medichat_call", "response_cleanup")
    
    # Cáº¥u hÃ¬nh Ä‘iá»ƒm káº¿t thÃºc
    builder.add_edge("response_cleanup", END)
    builder.add_edge("enhanced_response_cleanup", END)
    
    # BiÃªn dá»‹ch graph thÃ nh dáº¡ng thá»±c thi
    checkpointer = MemorySaver()
    return builder.compile(checkpointer=checkpointer)

# Chá»©c nÄƒng cháº¡y quy trÃ¬nh xá»­ lÃ½ chat
async def run_chat_flow(
    user_message: str,
    user_id: int,
    conversation_id: int,
    messages: List[Dict[str, str]],
    repository = None,
    llm_service = None
) -> Dict[str, Any]:
    """Cháº¡y luá»“ng xá»­ lÃ½ chat vÃ  tráº£ vá» káº¿t quáº£ vá»›i Ä‘áº§y Ä‘á»§ message IDs"""
    try:
        # Kiá»ƒm tra giá»›i háº¡n sá»‘ tin nháº¯n trong phiÃªn trÃ² chuyá»‡n
        limits = await check_conversation_limits(conversation_id, repository)
        if limits["limit_reached"]:
            # ÄÃ£ Ä‘áº¡t giá»›i háº¡n 30 tin nháº¯n
            # KhÃ´ng cáº§n lÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng vÃ¬ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u á»Ÿ API trÆ°á»›c Ä‘Ã³
            limit_message = "Báº¡n Ä‘Ã£ Ä‘áº¡t Ä‘áº¿n giá»›i háº¡n 30 tin nháº¯n trong phiÃªn trÃ² chuyá»‡n nÃ y. Vui lÃ²ng báº¯t Ä‘áº§u má»™t phiÃªn má»›i Ä‘á»ƒ tiáº¿p tá»¥c."
            assistant_message_db_obj = repository.add_message(conversation_id, "assistant", limit_message)
            
            logger.info(f"âš ï¸ ÄÃ£ Ä‘áº¡t giá»›i háº¡n 30 tin nháº¯n trong phiÃªn trÃ² chuyá»‡n {conversation_id}")
            
            return {
                "conversation_id": conversation_id,
                "user_message": {"role": "user", "content": user_message},
                "assistant_message": {"role": "assistant", "content": limit_message},
                "is_valid_scope": True,
                "need_more_info": False,
                "final_response": limit_message,
                "limit_reached": True,
                "message_count": limits["message_count"],
                "assistant_message_id_db": assistant_message_db_obj.message_id
            }
        
        # Khá»Ÿi táº¡o tráº¡ng thÃ¡i vá»›i Ä‘áº§y Ä‘á»§ cÃ¡c trÆ°á»ng
        state = ChatState(
            conversation_id=conversation_id,
            user_id=user_id,
            user_message=user_message,
            messages=messages,
            is_valid_scope=True,
            is_greeting=False,
            is_food_related=False,
            user_rejected_info=False,
            need_more_info=False,
            suggest_general_options=False,
            follow_up_question=None,
            collected_info={},
            medichat_prompt=None,
            medichat_response=None,
            recipe_results=None,
            beverage_results=None,  # â­ KHá»I Táº O BEVERAGE_RESULTS
            product_results=None,
            final_response=None,
            error=None,
            user_message_id_db=None,
            assistant_message_id_db=None,
            requests_food=None,      # â­ KHá»I Táº O REQUESTS_FOOD
            requests_beverage=None   # â­ KHá»I Táº O REQUESTS_BEVERAGE
        )
        
        # Táº¡o graph xá»­ lÃ½ chat
        chat_graph = create_chat_flow_graph(repository, llm_service)
        
        # Táº¡o thread id duy nháº¥t cho conversation
        thread_id = f"conversation_{conversation_id}"
        
        # Cháº¡y Ä‘á»“ thá»‹ vá»›i tráº¡ng thÃ¡i Ä‘Ã£ khá»Ÿi táº¡o
        result = await chat_graph.ainvoke(
            state, 
            config={"configurable": {"thread_id": thread_id}},
        )
        
        # Äáº£m báº£o luÃ´n cÃ³ final_response
        if not result.get("final_response"):
            if result.get("error"):
                result["final_response"] = "Xin lá»—i, cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh xá»­ lÃ½. Vui lÃ²ng thá»­ láº¡i sau."
            elif not result.get("is_valid_scope", True):
                result["final_response"] = ("Xin lá»—i, cÃ¢u há»i cá»§a báº¡n náº±m ngoÃ i pháº¡m vi tÆ° váº¥n cá»§a tÃ´i. "
                                          "TÃ´i chá»‰ cÃ³ thá»ƒ há»— trá»£ vá» cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n dinh dÆ°á»¡ng, sá»©c khá»e, "
                                          "mÃ³n Äƒn vÃ  Ä‘á»“ uá»‘ng.")
            else:
                result["final_response"] = "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ xá»­ lÃ½ yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i."
        
        # Äáº£m báº£o user_message luÃ´n lÃ  dictionary
        if "user_message" not in result or not isinstance(result["user_message"], dict):
            result["user_message"] = {"role": "user", "content": user_message}
        
        # Äáº£m báº£o cÃ³ assistant_message cho API tráº£ vá» vÃ  luÃ´n lÃ  dictionary
        if not result.get("assistant_message") or not isinstance(result["assistant_message"], dict):
            result["assistant_message"] = {
                "role": "assistant",
                "content": result.get("final_response", "")
            }
        
        # Log káº¿t quáº£ vá»›i message IDs
        logger.info("ğŸ¯ CHAT FLOW RESULT:")
        logger.info(f"   - user_message_id_db: {result.get('user_message_id_db')}")
        logger.info(f"   - assistant_message_id_db: {result.get('assistant_message_id_db')}")
        logger.info(f"   - is_valid_scope: {result.get('is_valid_scope')}")
        logger.info(f"   - suggest_general_options: {result.get('suggest_general_options')}")
        logger.info(f"   - final_response length: {len(result.get('final_response', ''))}")
        
        return result
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Lá»—i nghiÃªm trá»ng trong run_chat_flow: {str(e)}", exc_info=True)
        return {
            "conversation_id": conversation_id,
            "user_message": {"role": "user", "content": user_message},
            "assistant_message": {"role": "assistant", "content": "Xin lá»—i, cÃ³ lá»—i xáº£y ra trong há»‡ thá»‘ng. Vui lÃ²ng thá»­ láº¡i sau."},
            "is_valid_scope": False,
            "need_more_info": False,
            "final_response": "Xin lá»—i, cÃ³ lá»—i xáº£y ra trong há»‡ thá»‘ng. Vui lÃ²ng thá»­ láº¡i sau.",
            "error": str(e),
            "user_message_id_db": None,
            "assistant_message_id_db": None
        }

async def check_conversation_limits(conversation_id: int, repository) -> Dict[str, Any]:
    """Kiá»ƒm tra giá»›i háº¡n sá»‘ tin nháº¯n trong cuá»™c trÃ² chuyá»‡n"""
    try:
        messages = repository.get_messages(conversation_id)
        message_count = len(messages)
        limit_reached = message_count >= settings.MAX_HISTORY_MESSAGES
        
        return {
            "message_count": message_count,
            "limit_reached": limit_reached,
            "max_messages": settings.MAX_HISTORY_MESSAGES
        }
    except Exception as e:
        logger.error(f"ğŸ’¥ Lá»—i khi kiá»ƒm tra giá»›i háº¡n tin nháº¯n: {str(e)}")
        return {
            "message_count": 0,
            "limit_reached": False,
            "max_messages": settings.MAX_HISTORY_MESSAGES
        } 