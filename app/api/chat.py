from fastapi import APIRouter, Depends, HTTPException, Body, Query, BackgroundTasks
from typing import Dict, Any, Optional
from sqlalchemy.orm import Session
from fastapi.responses import StreamingResponse
import logging
import json
from app.db.database import get_db
from app.services.chat_service import ChatService
from app.services.chat_flow import run_chat_flow
# from app.middleware.auth import get_current_user_id
from app.middleware.auth import get_verified_user_from_backend, VerifiedUserInfo
from app.schemas.chat import ChatRequest, ChatResponse, NewChatResponse, ChatContentResponse
from app.config import settings

logger = logging.getLogger(__name__)

router = APIRouter()


@router.post("/chat", response_model=ChatResponse)
async def chat(
    request: ChatRequest,
    background_tasks: BackgroundTasks,
    verified_user: VerifiedUserInfo = Depends(get_verified_user_from_backend),
    db: Session = Depends(get_db)
):
    """G·ª≠i tin nh·∫Øn v√† nh·∫≠n ph·∫£n h·ªìi t·ª´ AI v·ªõi background DB operations"""
    chat_service = ChatService(db)
    
    # Ki·ªÉm tra quy·ªÅn truy c·∫≠p conversation n·∫øu c√≥
    if request.conversation_id:
        if not chat_service.repository.is_user_owner_of_conversation(verified_user.user_id, request.conversation_id):
            raise HTTPException(status_code=403, detail="Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p cu·ªôc tr√≤ chuy·ªán n√†y")
    
    # X·ª≠ l√Ω message v·ªõi background DB operations
    result, background_task_ids = await chat_service.process_message_with_background(
        user_id=verified_user.user_id,
        message_content=request.message,
        conversation_id=request.conversation_id
    )
    
    # Th√™m background tasks ƒë·ªÉ execute c√°c DB operations
    if background_task_ids:
        background_tasks.add_task(chat_service.execute_background_tasks, background_task_ids)
        logger.info(f"üöÄ ƒê√£ th√™m {len(background_task_ids)} background DB tasks")
    
    return result


@router.post("/stream-chat")
async def stream_chat(
    request: ChatRequest,
    verified_user: VerifiedUserInfo = Depends(get_verified_user_from_backend),
    db: Session = Depends(get_db)
):
    """G·ª≠i tin nh·∫Øn v√† nh·∫≠n ph·∫£n h·ªìi t·ª´ AI d·∫°ng streaming"""
    chat_service = ChatService(db)
    
    logger = logging.getLogger(__name__)
    
    if not request.conversation_id:
        conversation = chat_service.repository.get_latest_conversation(verified_user.user_id)
        if not conversation:
            conversation = chat_service.repository.create_conversation(verified_user.user_id)
            welcome_message = await chat_service.gemini_service.generate_welcome_message()
            chat_service.repository.add_message(conversation.conversation_id, "assistant", welcome_message)
            async def welcome_generator():
                yield f"data: {welcome_message}\n\n"
                yield "data: [DONE]\n\n"
            return StreamingResponse(welcome_generator(), media_type="text/event-stream")
        conversation_id = conversation.conversation_id
    else:
        if not chat_service.repository.is_user_owner_of_conversation(verified_user.user_id, request.conversation_id):
            raise HTTPException(status_code=403, detail="Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p cu·ªôc tr√≤ chuy·ªán n√†y")
        conversation = chat_service.repository.get_conversation_by_id(request.conversation_id)
        if not conversation:
            raise HTTPException(status_code=404, detail="Cu·ªôc tr√≤ chuy·ªán kh√¥ng t·ªìn t·∫°i")
        conversation_id = request.conversation_id
    
    chat_service.repository.add_message(conversation_id, "user", request.message)
    logger.info(f"ƒê√£ l∆∞u tin nh·∫Øn ng∆∞·ªùi d√πng tr∆∞·ªõc khi x·ª≠ l√Ω: {request.message[:50]}...")
    
    chat_history = chat_service.repository.get_messages(conversation_id, limit=10)
    
    async def response_generator():
        special_tokens = ["<|im_ending|>", "<|im_start|>"]
        full_response = ""
        error_indicators = ["Xin l·ªói, t√¥i ƒëang c√≥ v·∫•n ƒë·ªÅ", "Xin l·ªói, hi·ªán t√¥i kh√¥ng th·ªÉ k·∫øt n·ªëi"]
        
        try:
            if chat_service.llm_service._active_service is None:
                active_service = await chat_service.llm_service.initialize()
                yield f"data: {{\"info\": \"ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn d·ªãch v·ª•: {active_service}\"}}\n\n"
            else:
                active_service = chat_service.llm_service._active_service.value
                yield f"data: {{\"info\": \"ƒêang s·ª≠ d·ª•ng d·ªãch v·ª•: {active_service}\"}}\n\n"
            
            try:
                result = await run_chat_flow(
                    user_message=request.message,
                    user_id=verified_user.user_id,
                    conversation_id=conversation_id,
                    messages=chat_history,
                    repository=chat_service.repository,
                    llm_service=chat_service.llm_service
                )
            except Exception as e:
                logger.error(f"L·ªói khi ch·∫°y LangGraph flow: {str(e)}")
                chat_service.repository.add_message(conversation_id, "user", request.message)
                error_message = "Xin l·ªói, c√≥ l·ªói x·ª≠ l√Ω trong h·ªá th·ªëng. T√¥i s·∫Ω ghi nh·∫≠n c√¢u h·ªèi c·ªßa b·∫°n v√† tr·∫£ l·ªùi sau."
                yield f"data: {error_message}\n\n"
                yield "data: [DONE]\n\n"
                return
            
            if "final_response" in result and result["final_response"]:
                response = result["final_response"]
                yield f"data: {response}\n\n"
                
                # ‚≠ê G·ª¨I AVAILABLE_PRODUCTS SAU KHI STREAM K·∫æT TH√öC
                available_products = result.get("available_products", [])
                if available_products:
                    logger.info(f"üéØ Streaming: G·ª≠i {len(available_products)} s·∫£n ph·∫©m c√≥ s·∫µn")
                    products_data = {
                        "type": "available_products",
                        "data": available_products
                    }
                    yield f"data: {json.dumps(products_data, ensure_ascii=False)}\n\n"
                else:
                    logger.info("üì¶ Streaming: Kh√¥ng c√≥ s·∫£n ph·∫©m available_products ƒë·ªÉ g·ª≠i")
                
                yield "data: [DONE]\n\n"
                return
            
            if "need_more_info" in result and result["need_more_info"] and "assistant_message" in result:
                follow_up = result["assistant_message"]["content"]
                yield f"data: {follow_up}\n\n"
                yield "data: [DONE]\n\n"
                return
            
            medichat_prompt = result.get("medichat_prompt")
            if not medichat_prompt:
                medichat_prompt = await chat_service.gemini_service.create_medichat_prompt(messages=chat_history)
            
            medichat_messages = [
                {
                    "role": "system", 
                    "content": settings.MEDICHAT_SYSTEM_PROMPT
                },
                {
                    "role": "user",
                    "content": medichat_prompt
                }
            ]
            
            logger.info(f"ƒêang g·ª≠i prompt ƒë·∫øn Medichat: {medichat_prompt}")
            async for chunk in chat_service.llm_service.generate_response(medichat_messages):
                logger.debug(f"Nh·∫≠n ƒë∆∞·ª£c chunk: {chunk}")
                
                for token in special_tokens:
                    chunk = chunk.replace(token, "")
                
                if chunk.strip():
                    full_response += chunk
                    yield f"data: {chunk}\n\n"
            
            is_error_response = any(indicator in full_response for indicator in error_indicators)
            if is_error_response:
                logger.warning(f"Ph√°t hi·ªán th√¥ng b√°o l·ªói trong ph·∫£n h·ªìi: {full_response}")
                for indicator in error_indicators:
                    if indicator in full_response:
                        error_end_pos = full_response.find(".", full_response.find(indicator)) + 1
                        if error_end_pos > 0:
                            full_response = full_response[:error_end_pos].strip()
                            break
            
            if full_response.strip() and not is_error_response:
                polished_response = await chat_service.gemini_service.polish_response(full_response, medichat_prompt)
                
                chat_service.repository.add_message(conversation_id, "assistant", polished_response)
                logger.info(f"ƒê√£ l∆∞u ph·∫£n h·ªìi ƒë√£ ƒëi·ªÅu ch·ªânh: {polished_response[:50]}...")
                
                if polished_response != full_response:
                    yield f"data: {{\"replace\": \"{json.dumps(polished_response)}\"}}\n\n"
                
                # ‚≠ê G·ª¨I AVAILABLE_PRODUCTS SAU KHI STREAM K·∫æT TH√öC
                available_products = result.get("available_products", [])
                if available_products:
                    logger.info(f"üéØ Streaming: G·ª≠i {len(available_products)} s·∫£n ph·∫©m c√≥ s·∫µn")
                    products_data = {
                        "type": "available_products", 
                        "data": available_products
                    }
                    yield f"data: {json.dumps(products_data, ensure_ascii=False)}\n\n"
                else:
                    logger.info("üì¶ Streaming: Kh√¥ng c√≥ s·∫£n ph·∫©m available_products ƒë·ªÉ g·ª≠i")
                
            else:
                if not full_response.strip():
                    error_message = "Xin l·ªói, kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ h·ªá th·ªëng AI. Vui l√≤ng th·ª≠ l·∫°i sau."
                else:
                    error_message = full_response
                
                yield f"data: {error_message}\n\n"
                chat_service.repository.add_message(conversation_id, "assistant", error_message)
                logger.warning(f"ƒê√£ l∆∞u th√¥ng b√°o l·ªói: {error_message}")
                
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω ph·∫£n h·ªìi: {str(e)}")
            error_message = "Xin l·ªói, hi·ªán t√¥i kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi h·ªá th·ªëng tr√≠ tu·ªá nh√¢n t·∫°o. Vui l√≤ng th·ª≠ l·∫°i sau."
            yield f"data: {error_message}\n\n"
            
            chat_service.repository.add_message(conversation_id, "assistant", error_message)
        
        yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        response_generator(),
        media_type="text/event-stream"
    )


@router.post("/newChat", response_model=NewChatResponse)
async def new_chat(
    verified_user: VerifiedUserInfo = Depends(get_verified_user_from_backend),
    db: Session = Depends(get_db)
):
    """T·∫°o cu·ªôc tr√≤ chuy·ªán m·ªõi"""
    chat_service = ChatService(db)
    result = chat_service.create_new_chat(verified_user.user_id)
    return result


@router.get("/chatContent", response_model=ChatContentResponse)
async def get_chat_content(
    conversation_id: Optional[int] = None,
    verified_user: VerifiedUserInfo = Depends(get_verified_user_from_backend),
    db: Session = Depends(get_db)
):
    """L·∫•y n·ªôi dung cu·ªôc tr√≤ chuy·ªán bao g·ªìm s·∫£n ph·∫©m c√≥ s·∫µn"""
    chat_service = ChatService(db)
    result = await chat_service.get_chat_content(verified_user.user_id, conversation_id)
    return result


# Endpoint test kh√¥ng y√™u c·∫ßu authentication
@router.get("/test-chatContent")
async def test_get_chat_content(
    conversation_id: Optional[int] = Query(None),
    db: Session = Depends(get_db)
):
    """Endpoint test ƒë·ªÉ l·∫•y n·ªôi dung cu·ªôc tr√≤ chuy·ªán m√† kh√¥ng c·∫ßn authentication, bao g·ªìm s·∫£n ph·∫©m c√≥ s·∫µn"""
    chat_service = ChatService(db)
    
    if not conversation_id:
        return {
            "conversation_id": None,
            "user_id": None,
            "created_at": None,
            "messages": [],
            "available_products": [],
            "error": "C·∫ßn cung c·∫•p conversation_id"
        }
    
    try:
        # L·∫•y conversation m√† kh√¥ng ki·ªÉm tra user ownership
        conversation = chat_service.repository.get_conversation_by_id(conversation_id)
        if not conversation:
            return {
                "conversation_id": conversation_id,
                "user_id": None,
                "created_at": None,
                "messages": [],
                "available_products": [],
                "error": "Cu·ªôc tr√≤ chuy·ªán kh√¥ng t·ªìn t·∫°i"
            }
        
        messages = chat_service.repository.get_messages(conversation_id)
        logger.info(f"Retrieved {len(messages)} messages for conversation {conversation_id}")
        
        # L·∫•y s·∫£n ph·∫©m c√≥ s·∫µn
        available_products = await chat_service._get_available_products_for_conversation(conversation_id)
        logger.info(f"Retrieved {len(available_products)} available products for conversation {conversation_id}")
        
        formatted_messages = []
        for i, msg in enumerate(messages):
            try:
                formatted_msg = {
                    "role": msg["role"],
                    "content": msg["content"],
                    "timestamp": None  # get_messages kh√¥ng tr·∫£ v·ªÅ timestamp
                }
                formatted_messages.append(formatted_msg)
            except Exception as msg_error:
                logger.error(f"Error formatting message {i}: {msg_error}, msg type: {type(msg)}, msg: {msg}")
                continue
        
        return {
            "conversation_id": conversation.conversation_id,
            "user_id": conversation.user_id,
            "created_at": conversation.created_at.isoformat() if conversation.created_at else None,
            "messages": formatted_messages,
            "available_products": available_products
        }
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y chat content: {str(e)}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return {
            "conversation_id": conversation_id,
            "user_id": None,
            "created_at": None,
            "messages": [],
            "available_products": [],
            "error": f"L·ªói server: {str(e)}"
        }


@router.get("/background-task-status/{task_id}")
async def get_background_task_status(
    task_id: str,
    verified_user: VerifiedUserInfo = Depends(get_verified_user_from_backend),
    db: Session = Depends(get_db)
):
    """
    L·∫•y tr·∫°ng th√°i c·ªßa background task.
    Endpoint n√†y d√πng cho monitoring/debugging.
    """
    chat_service = ChatService(db)
    status = chat_service.get_background_task_status(task_id)
    
    if status is None:
        raise HTTPException(status_code=404, detail="Task kh√¥ng t·ªìn t·∫°i")
        
    return {
        "task_id": task_id,
        "status": status["status"],
        "details": status
    } 